{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ad6eef3",
   "metadata": {},
   "source": [
    "# Random Portfolio Analysis - Complete Risk Assessment\n",
    "\n",
    "This notebook demonstrates a comprehensive portfolio analysis workflow using the Portfolio Analytics AI package. We'll:\n",
    "\n",
    "1. **Query Available Data** - Discover stocks, ETFs, and risk-free rates in cache\n",
    "2. **Create Random Portfolio** - Build a 40-stock portfolio with random weights\n",
    "3. **Select Random Benchmark** - Choose an ETF for performance comparison\n",
    "4. **Risk Analysis** - Calculate all available risk metrics\n",
    "5. **Visualizations** - Create comprehensive charts and dashboards\n",
    "\n",
    "## Features Demonstrated:\n",
    "- Complete data discovery and validation\n",
    "- Random portfolio construction with proper weight normalization\n",
    "- Comprehensive risk metrics calculation\n",
    "- Professional-grade visualization suite\n",
    "- Risk-adjusted performance analysis with real risk-free rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f91f76",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup\n",
    "\n",
    "Import all necessary libraries for portfolio analysis, risk calculation, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f633d0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import portfolio analytics modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from portfolio_analytics.data_provider import DataProvider\n",
    "from portfolio_analytics.portfolio import Portfolio\n",
    "from portfolio_analytics.performance import PerformanceAnalyzer\n",
    "from portfolio_analytics.risk_models import RiskModel\n",
    "from portfolio_analytics.visualization import PortfolioVisualizer\n",
    "\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üìÖ Analysis date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Setup paths\n",
    "sample_data_dir = '../sample_data'\n",
    "cache_db_path = f'{sample_data_dir}/market_data.db'\n",
    "\n",
    "print(f\"üìÅ Using cache database: {cache_db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c645b9",
   "metadata": {},
   "source": [
    "## 2. Query Available Data\n",
    "\n",
    "Discover and analyze what stocks, ETFs, and risk-free rate data are available in our cache using the new DataProvider methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33bd1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataProvider with cache\n",
    "data_provider = DataProvider(cache=True, cache_db=cache_db_path, debug=True)\n",
    "\n",
    "print(\"üîç Querying available data from cache...\\n\")\n",
    "\n",
    "# Get all available stocks (excluding ETFs)\n",
    "available_stocks = data_provider.get_cached_stocks(include_etfs=False)\n",
    "print(f\"üìà Available stocks: {len(available_stocks)}\")\n",
    "if available_stocks:\n",
    "    print(f\"   Sample stocks: {available_stocks[:10]}\")\n",
    "\n",
    "# Get all available ETFs\n",
    "available_etfs = data_provider.get_cached_etfs()\n",
    "print(f\"\\nüéØ Available ETFs: {len(available_etfs)}\")\n",
    "if available_etfs:\n",
    "    print(f\"   Sample ETFs: {available_etfs[:10]}\")\n",
    "\n",
    "# Get risk-free rate information\n",
    "risk_free_metadata = data_provider.get_risk_free_rate_metadata()\n",
    "print(f\"\\nüí∞ Risk-free rate information:\")\n",
    "print(f\"   Symbol: {risk_free_metadata['symbol']}\")\n",
    "print(f\"   Name: {risk_free_metadata['name']}\")\n",
    "print(f\"   Currency: {risk_free_metadata['currency']}\")\n",
    "print(f\"   Frequency: {risk_free_metadata['frequency']}\")\n",
    "\n",
    "# Get detailed symbol information\n",
    "symbols_info = data_provider.get_cached_symbols_info()\n",
    "print(f\"\\nüìä Detailed symbol information available for {len(symbols_info)} symbols\")\n",
    "\n",
    "# Analyze data quality\n",
    "if symbols_info:\n",
    "    # Filter stocks and ETFs with sufficient data (at least 1000 data points)\n",
    "    quality_stocks = [\n",
    "        symbol for symbol in available_stocks \n",
    "        if symbol in symbols_info and symbols_info[symbol]['count'] >= 1000\n",
    "    ]\n",
    "    \n",
    "    quality_etfs = [\n",
    "        symbol for symbol in available_etfs \n",
    "        if symbol in symbols_info and symbols_info[symbol]['count'] >= 1000\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n‚úÖ High-quality data (1000+ points):\")\n",
    "    print(f\"   Quality stocks: {len(quality_stocks)}\")\n",
    "    print(f\"   Quality ETFs: {len(quality_etfs)}\")\n",
    "    \n",
    "    # Date range analysis\n",
    "    if symbols_info:\n",
    "        start_dates = [info['start_date'] for info in symbols_info.values()]\n",
    "        end_dates = [info['end_date'] for info in symbols_info.values()]\n",
    "        print(f\"   Data range: {min(start_dates)} to {max(end_dates)}\")\n",
    "        \n",
    "        # Show data point statistics\n",
    "        data_points = [info['count'] for info in symbols_info.values()]\n",
    "        print(f\"   Avg data points: {np.mean(data_points):.0f}\")\n",
    "        print(f\"   Max data points: {max(data_points):,}\")\n",
    "    \n",
    "    # Use quality data for portfolio construction\n",
    "    portfolio_stocks = quality_stocks if quality_stocks else available_stocks\n",
    "    benchmark_etfs = quality_etfs if quality_etfs else available_etfs\n",
    "    \n",
    "    print(f\"\\nüé≤ Ready for portfolio construction:\")\n",
    "    print(f\"   Stocks pool: {len(portfolio_stocks)}\")\n",
    "    print(f\"   ETFs pool: {len(benchmark_etfs)}\")\n",
    "else:\n",
    "    print(\"‚ùå No detailed symbol information available\")\n",
    "    portfolio_stocks = available_stocks\n",
    "    benchmark_etfs = available_etfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3daed17",
   "metadata": {},
   "source": [
    "## 3. Create Random Portfolio\n",
    "\n",
    "Build a random portfolio of 40 stocks with random weights that sum to 100%, and select a random ETF as benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c4a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio construction parameters\n",
    "NUM_STOCKS = 40\n",
    "MIN_WEIGHT = 0.005  # 0.5% minimum weight\n",
    "MAX_WEIGHT = 0.15   # 15% maximum weight\n",
    "\n",
    "print(f\"üé≤ Creating random portfolio with {NUM_STOCKS} stocks...\")\n",
    "\n",
    "# Ensure we have enough stocks\n",
    "if len(portfolio_stocks) < NUM_STOCKS:\n",
    "    NUM_STOCKS = min(len(portfolio_stocks), 40)\n",
    "    print(f\"‚ö†Ô∏è  Adjusting to {NUM_STOCKS} stocks (limited by available data)\")\n",
    "\n",
    "# Randomly select stocks for the portfolio\n",
    "selected_stocks = random.sample(portfolio_stocks, NUM_STOCKS)\n",
    "print(f\"‚úÖ Selected {NUM_STOCKS} random stocks:\")\n",
    "print(f\"   {selected_stocks}\")\n",
    "\n",
    "# Generate random weights using Dirichlet distribution for more realistic weights\n",
    "# This ensures weights sum to 1 and creates more varied weight distributions\n",
    "alpha = np.ones(NUM_STOCKS)  # Uniform Dirichlet\n",
    "raw_weights = np.random.dirichlet(alpha)\n",
    "\n",
    "# Apply min/max constraints\n",
    "weights = np.maximum(raw_weights, MIN_WEIGHT)\n",
    "weights = np.minimum(weights, MAX_WEIGHT)\n",
    "\n",
    "# Normalize to sum to 1\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "# Create weights dictionary\n",
    "portfolio_weights = {stock: weight for stock, weight in zip(selected_stocks, weights)}\n",
    "\n",
    "print(f\"\\nüìä Portfolio weights generated:\")\n",
    "print(f\"   Sum of weights: {sum(weights):.6f}\")\n",
    "print(f\"   Min weight: {min(weights):.4f} ({min(weights)*100:.2f}%)\")\n",
    "print(f\"   Max weight: {max(weights):.4f} ({max(weights)*100:.2f}%)\")\n",
    "print(f\"   Mean weight: {np.mean(weights):.4f} ({np.mean(weights)*100:.2f}%)\")\n",
    "\n",
    "# Display top 10 holdings\n",
    "sorted_holdings = sorted(portfolio_weights.items(), key=lambda x: x[1], reverse=True)\n",
    "print(f\"\\nüîù Top 10 holdings:\")\n",
    "for i, (stock, weight) in enumerate(sorted_holdings[:10], 1):\n",
    "    print(f\"   {i:2d}. {stock:6s}: {weight*100:5.2f}%\")\n",
    "\n",
    "# Select random benchmark ETF\n",
    "if benchmark_etfs:\n",
    "    benchmark_symbol = random.choice(benchmark_etfs)\n",
    "    print(f\"\\nüéØ Random benchmark selected: {benchmark_symbol}\")\n",
    "    \n",
    "    # Get benchmark info if available\n",
    "    if benchmark_symbol in symbols_info:\n",
    "        bench_info = symbols_info[benchmark_symbol]\n",
    "        print(f\"   Data points: {bench_info['count']:,}\")\n",
    "        print(f\"   Date range: {bench_info['start_date']} to {bench_info['end_date']}\")\n",
    "else:\n",
    "    benchmark_symbol = None\n",
    "    print(\"\\n‚ùå No benchmark ETFs available\")\n",
    "\n",
    "print(f\"\\n‚úÖ Portfolio construction complete!\")\n",
    "print(f\"   Portfolio: {NUM_STOCKS} stocks with diversified weights\")\n",
    "print(f\"   Benchmark: {benchmark_symbol if benchmark_symbol else 'None'}\")\n",
    "print(f\"   Risk-free rate: {risk_free_metadata['symbol']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd873b4",
   "metadata": {},
   "source": [
    "## 4. Load Price Data\n",
    "\n",
    "Fetch historical price data for the selected portfolio stocks and benchmark ETF for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aac674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define analysis period (3 years for comprehensive analysis)\n",
    "end_date = datetime.now() - timedelta(days=1)\n",
    "start_date = end_date - timedelta(days=3*365)\n",
    "\n",
    "start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"üìÖ Loading price data for period: {start_date_str} to {end_date_str}\")\n",
    "\n",
    "# Load portfolio stock data\n",
    "print(f\"\\nüìà Loading data for {len(selected_stocks)} portfolio stocks...\")\n",
    "portfolio_data = data_provider.get_price_data(\n",
    "    symbols=selected_stocks,\n",
    "    start_date=start_date_str,\n",
    "    end_date=end_date_str\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Portfolio data loaded: {portfolio_data.shape}\")\n",
    "print(f\"   Date range: {portfolio_data.index[0].strftime('%Y-%m-%d')} to {portfolio_data.index[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"   Missing data points: {portfolio_data.isnull().sum().sum()}\")\n",
    "\n",
    "# Load benchmark data\n",
    "if benchmark_symbol:\n",
    "    print(f\"\\nüéØ Loading benchmark data for {benchmark_symbol}...\")\n",
    "    benchmark_data = data_provider.get_price_data(\n",
    "        symbols=benchmark_symbol,\n",
    "        start_date=start_date_str,\n",
    "        end_date=end_date_str\n",
    "    )\n",
    "    \n",
    "    if not benchmark_data.empty:\n",
    "        print(f\"‚úÖ Benchmark data loaded: {benchmark_data.shape}\")\n",
    "        benchmark_prices = benchmark_data[benchmark_symbol]\n",
    "    else:\n",
    "        print(f\"‚ùå No benchmark data available for {benchmark_symbol}\")\n",
    "        benchmark_prices = None\n",
    "        benchmark_symbol = None\n",
    "else:\n",
    "    benchmark_prices = None\n",
    "\n",
    "# Load risk-free rate data\n",
    "print(f\"\\nüí∞ Loading risk-free rate data...\")\n",
    "try:\n",
    "    risk_free_data = data_provider.get_risk_free_rate(start_date_str, end_date_str)\n",
    "    if risk_free_data is not None and not risk_free_data.empty:\n",
    "        print(f\"‚úÖ Risk-free rate data loaded: {len(risk_free_data)} data points\")\n",
    "        print(f\"   Current rate: {risk_free_data.iloc[-1]:.4f} ({risk_free_data.iloc[-1]*100:.2f}%)\")\n",
    "        print(f\"   Average rate: {risk_free_data.mean():.4f} ({risk_free_data.mean()*100:.2f}%)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Risk-free rate data not available, using 2% default\")\n",
    "        risk_free_data = None\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Error loading risk-free rate: {e}\")\n",
    "    risk_free_data = None\n",
    "\n",
    "# Data quality check\n",
    "print(f\"\\nüìä Data quality summary:\")\n",
    "print(f\"   Portfolio stocks: {len([col for col in portfolio_data.columns if not portfolio_data[col].isnull().all()])}/{len(selected_stocks)} with data\")\n",
    "print(f\"   Benchmark: {'‚úÖ' if benchmark_prices is not None else '‚ùå'}\")\n",
    "print(f\"   Risk-free rate: {'‚úÖ' if risk_free_data is not None else '‚ùå'}\")\n",
    "\n",
    "# Remove stocks with insufficient data\n",
    "valid_stocks = [col for col in portfolio_data.columns if not portfolio_data[col].isnull().all()]\n",
    "if len(valid_stocks) < len(selected_stocks):\n",
    "    print(f\"‚ö†Ô∏è  Removing {len(selected_stocks) - len(valid_stocks)} stocks with no data\")\n",
    "    portfolio_data = portfolio_data[valid_stocks]\n",
    "    # Update portfolio weights\n",
    "    portfolio_weights = {stock: weight for stock, weight in portfolio_weights.items() if stock in valid_stocks}\n",
    "    # Renormalize weights\n",
    "    total_weight = sum(portfolio_weights.values())\n",
    "    portfolio_weights = {stock: weight/total_weight for stock, weight in portfolio_weights.items()}\n",
    "\n",
    "print(f\"‚úÖ Final portfolio: {len(portfolio_weights)} stocks ready for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef7ca69",
   "metadata": {},
   "source": [
    "## 5. Portfolio Construction and Returns Calculation\n",
    "\n",
    "Create the Portfolio object and calculate returns for portfolio and benchmark analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb54523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Portfolio object\n",
    "print(\"üèóÔ∏è  Creating Portfolio object...\")\n",
    "portfolio = Portfolio(\n",
    "    data_provider=data_provider,\n",
    "    symbols=list(portfolio_weights.keys()),\n",
    "    weights=list(portfolio_weights.values())\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Portfolio created with {len(portfolio_weights)} assets\")\n",
    "\n",
    "# Calculate returns\n",
    "print(\"\\nüìä Calculating returns...\")\n",
    "\n",
    "# Portfolio returns (daily)\n",
    "portfolio_returns = portfolio_data.pct_change().dropna()\n",
    "print(f\"   Portfolio stock returns: {portfolio_returns.shape}\")\n",
    "\n",
    "# Calculate weighted portfolio returns\n",
    "weights_array = np.array([portfolio_weights[stock] for stock in portfolio_returns.columns])\n",
    "portfolio_daily_returns = (portfolio_returns * weights_array).sum(axis=1)\n",
    "print(f\"   Weighted portfolio returns: {len(portfolio_daily_returns)}\")\n",
    "\n",
    "# Benchmark returns\n",
    "if benchmark_prices is not None:\n",
    "    benchmark_returns = benchmark_prices.pct_change().dropna()\n",
    "    print(f\"   Benchmark returns: {len(benchmark_returns)}\")\n",
    "    \n",
    "    # Align benchmark returns with portfolio returns\n",
    "    common_dates = portfolio_daily_returns.index.intersection(benchmark_returns.index)\n",
    "    portfolio_daily_returns = portfolio_daily_returns.loc[common_dates]\n",
    "    benchmark_returns = benchmark_returns.loc[common_dates]\n",
    "    print(f\"   Aligned returns: {len(common_dates)} common dates\")\n",
    "else:\n",
    "    benchmark_returns = None\n",
    "\n",
    "# Calculate summary statistics\n",
    "print(f\"\\nüìà Portfolio performance summary:\")\n",
    "print(f\"   Daily return mean: {portfolio_daily_returns.mean():.6f} ({portfolio_daily_returns.mean()*252*100:.2f}% annualized)\")\n",
    "print(f\"   Daily return std: {portfolio_daily_returns.std():.6f} ({portfolio_daily_returns.std()*np.sqrt(252)*100:.2f}% annualized)\")\n",
    "print(f\"   Total return: {(1 + portfolio_daily_returns).prod() - 1:.4f} ({((1 + portfolio_daily_returns).prod() - 1)*100:.2f}%)\")\n",
    "\n",
    "if benchmark_returns is not None:\n",
    "    print(f\"\\nüéØ Benchmark performance summary:\")\n",
    "    print(f\"   Daily return mean: {benchmark_returns.mean():.6f} ({benchmark_returns.mean()*252*100:.2f}% annualized)\")\n",
    "    print(f\"   Daily return std: {benchmark_returns.std():.6f} ({benchmark_returns.std()*np.sqrt(252)*100:.2f}% annualized)\")\n",
    "    print(f\"   Total return: {(1 + benchmark_returns).prod() - 1:.4f} ({((1 + benchmark_returns).prod() - 1)*100:.2f}%)\")\n",
    "\n",
    "# Align risk-free rate data if available\n",
    "if risk_free_data is not None:\n",
    "    # Convert annual risk-free rate to daily\n",
    "    risk_free_daily = risk_free_data / 252\n",
    "    # Align with portfolio returns\n",
    "    common_rf_dates = portfolio_daily_returns.index.intersection(risk_free_daily.index)\n",
    "    if len(common_rf_dates) > 0:\n",
    "        risk_free_aligned = risk_free_daily.loc[common_rf_dates]\n",
    "        portfolio_returns_aligned = portfolio_daily_returns.loc[common_rf_dates]\n",
    "        if benchmark_returns is not None:\n",
    "            benchmark_returns_aligned = benchmark_returns.loc[common_rf_dates]\n",
    "        print(f\"   Risk-free rate aligned: {len(common_rf_dates)} dates\")\n",
    "        print(f\"   Avg daily risk-free rate: {risk_free_aligned.mean():.6f} ({risk_free_aligned.mean()*252*100:.2f}% annualized)\")\n",
    "    else:\n",
    "        risk_free_aligned = None\n",
    "        portfolio_returns_aligned = portfolio_daily_returns\n",
    "        benchmark_returns_aligned = benchmark_returns if benchmark_returns is not None else None\n",
    "else:\n",
    "    risk_free_aligned = None\n",
    "    portfolio_returns_aligned = portfolio_daily_returns\n",
    "    benchmark_returns_aligned = benchmark_returns if benchmark_returns is not None else None\n",
    "\n",
    "print(f\"\\n‚úÖ Returns calculation complete!\")\n",
    "print(f\"   Analysis period: {portfolio_daily_returns.index[0].strftime('%Y-%m-%d')} to {portfolio_daily_returns.index[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"   Trading days: {len(portfolio_daily_returns)}\")\n",
    "print(f\"   Data alignment: Portfolio, Benchmark, Risk-free rate all aligned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4fe1a3",
   "metadata": {},
   "source": [
    "## 6. Comprehensive Risk Metrics Calculation\n",
    "\n",
    "Calculate all available risk metrics including VaR, Expected Shortfall, Maximum Drawdown, and risk-adjusted ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2282bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize risk model and performance analyzer\n",
    "print(\"üîß Initializing risk analysis tools...\")\n",
    "risk_model = RiskModel()\n",
    "performance_analyzer = PerformanceAnalyzer()\n",
    "\n",
    "print(\"üìä Calculating comprehensive risk metrics...\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# PORTFOLIO RISK METRICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üéØ PORTFOLIO RISK METRICS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Basic statistics\n",
    "annual_return = portfolio_returns_aligned.mean() * 252\n",
    "annual_volatility = portfolio_returns_aligned.std() * np.sqrt(252)\n",
    "print(f\"Annual Return: {annual_return:.4f} ({annual_return*100:.2f}%)\")\n",
    "print(f\"Annual Volatility: {annual_volatility:.4f} ({annual_volatility*100:.2f}%)\")\n",
    "\n",
    "# Risk-adjusted ratios\n",
    "if risk_free_aligned is not None:\n",
    "    avg_risk_free = risk_free_aligned.mean() * 252\n",
    "    sharpe_ratio = (annual_return - avg_risk_free) / annual_volatility\n",
    "    print(f\"Risk-free Rate: {avg_risk_free:.4f} ({avg_risk_free*100:.2f}%)\")\n",
    "    print(f\"Sharpe Ratio: {sharpe_ratio:.4f}\")\n",
    "else:\n",
    "    sharpe_ratio = annual_return / annual_volatility\n",
    "    print(f\"Sharpe Ratio (no RF): {sharpe_ratio:.4f}\")\n",
    "\n",
    "# Maximum Drawdown\n",
    "cumulative_returns = (1 + portfolio_returns_aligned).cumprod()\n",
    "running_max = cumulative_returns.expanding().max()\n",
    "drawdown = (cumulative_returns - running_max) / running_max\n",
    "max_drawdown = drawdown.min()\n",
    "print(f\"Maximum Drawdown: {max_drawdown:.4f} ({max_drawdown*100:.2f}%)\")\n",
    "\n",
    "# Calmar Ratio\n",
    "calmar_ratio = annual_return / abs(max_drawdown) if max_drawdown != 0 else 0\n",
    "print(f\"Calmar Ratio: {calmar_ratio:.4f}\")\n",
    "\n",
    "# Sortino Ratio (downside deviation)\n",
    "downside_returns = portfolio_returns_aligned[portfolio_returns_aligned < 0]\n",
    "if len(downside_returns) > 0:\n",
    "    downside_volatility = downside_returns.std() * np.sqrt(252)\n",
    "    if risk_free_aligned is not None:\n",
    "        sortino_ratio = (annual_return - avg_risk_free) / downside_volatility\n",
    "    else:\n",
    "        sortino_ratio = annual_return / downside_volatility\n",
    "    print(f\"Downside Volatility: {downside_volatility:.4f} ({downside_volatility*100:.2f}%)\")\n",
    "    print(f\"Sortino Ratio: {sortino_ratio:.4f}\")\n",
    "else:\n",
    "    sortino_ratio = float('inf')\n",
    "    print(\"Sortino Ratio: ‚àû (no negative returns)\")\n",
    "\n",
    "# Value at Risk (VaR) and Expected Shortfall (ES)\n",
    "try:\n",
    "    var_95 = risk_model.value_at_risk(portfolio_returns_aligned, confidence_level=0.95)\n",
    "    var_99 = risk_model.value_at_risk(portfolio_returns_aligned, confidence_level=0.99)\n",
    "    es_95 = risk_model.expected_shortfall(portfolio_returns_aligned, confidence_level=0.95)\n",
    "    es_99 = risk_model.expected_shortfall(portfolio_returns_aligned, confidence_level=0.99)\n",
    "    \n",
    "    print(f\"VaR (95%): {var_95:.4f} ({var_95*100:.2f}%)\")\n",
    "    print(f\"VaR (99%): {var_99:.4f} ({var_99*100:.2f}%)\")\n",
    "    print(f\"Expected Shortfall (95%): {es_95:.4f} ({es_95*100:.2f}%)\")\n",
    "    print(f\"Expected Shortfall (99%): {es_99:.4f} ({es_99*100:.2f}%)\")\n",
    "except Exception as e:\n",
    "    print(f\"VaR/ES calculation error: {e}\")\n",
    "    var_95 = var_99 = es_95 = es_99 = None\n",
    "\n",
    "# Skewness and Kurtosis\n",
    "skewness = portfolio_returns_aligned.skew()\n",
    "kurtosis = portfolio_returns_aligned.kurtosis()\n",
    "print(f\"Skewness: {skewness:.4f}\")\n",
    "print(f\"Excess Kurtosis: {kurtosis:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# BENCHMARK COMPARISON (if available)\n",
    "# ============================================================================\n",
    "\n",
    "if benchmark_returns_aligned is not None:\n",
    "    print(f\"\\nüéØ BENCHMARK COMPARISON ({benchmark_symbol})\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Benchmark statistics\n",
    "    benchmark_annual_return = benchmark_returns_aligned.mean() * 252\n",
    "    benchmark_annual_volatility = benchmark_returns_aligned.std() * np.sqrt(252)\n",
    "    \n",
    "    print(f\"Benchmark Annual Return: {benchmark_annual_return:.4f} ({benchmark_annual_return*100:.2f}%)\")\n",
    "    print(f\"Benchmark Annual Volatility: {benchmark_annual_volatility:.4f} ({benchmark_annual_volatility*100:.2f}%)\")\n",
    "    \n",
    "    # Benchmark Sharpe ratio\n",
    "    if risk_free_aligned is not None:\n",
    "        benchmark_sharpe = (benchmark_annual_return - avg_risk_free) / benchmark_annual_volatility\n",
    "    else:\n",
    "        benchmark_sharpe = benchmark_annual_return / benchmark_annual_volatility\n",
    "    print(f\"Benchmark Sharpe Ratio: {benchmark_sharpe:.4f}\")\n",
    "    \n",
    "    # Relative performance\n",
    "    excess_return = annual_return - benchmark_annual_return\n",
    "    print(f\"Excess Return: {excess_return:.4f} ({excess_return*100:.2f}%)\")\n",
    "    \n",
    "    # Beta calculation\n",
    "    covariance = np.cov(portfolio_returns_aligned, benchmark_returns_aligned)[0, 1]\n",
    "    benchmark_variance = benchmark_returns_aligned.var()\n",
    "    beta = covariance / benchmark_variance\n",
    "    print(f\"Beta: {beta:.4f}\")\n",
    "    \n",
    "    # Alpha calculation\n",
    "    if risk_free_aligned is not None:\n",
    "        alpha = annual_return - (avg_risk_free + beta * (benchmark_annual_return - avg_risk_free))\n",
    "    else:\n",
    "        alpha = annual_return - beta * benchmark_annual_return\n",
    "    print(f\"Alpha: {alpha:.4f} ({alpha*100:.2f}%)\")\n",
    "    \n",
    "    # Tracking Error\n",
    "    tracking_error = (portfolio_returns_aligned - benchmark_returns_aligned).std() * np.sqrt(252)\n",
    "    print(f\"Tracking Error: {tracking_error:.4f} ({tracking_error*100:.2f}%)\")\n",
    "    \n",
    "    # Information Ratio\n",
    "    information_ratio = excess_return / tracking_error if tracking_error != 0 else 0\n",
    "    print(f\"Information Ratio: {information_ratio:.4f}\")\n",
    "    \n",
    "    # Correlation\n",
    "    correlation = portfolio_returns_aligned.corr(benchmark_returns_aligned)\n",
    "    print(f\"Correlation: {correlation:.4f}\")\n",
    "    \n",
    "    # Up/Down capture ratios\n",
    "    up_markets = benchmark_returns_aligned > 0\n",
    "    down_markets = benchmark_returns_aligned < 0\n",
    "    \n",
    "    if up_markets.sum() > 0:\n",
    "        up_capture = (portfolio_returns_aligned[up_markets].mean() / \n",
    "                     benchmark_returns_aligned[up_markets].mean())\n",
    "        print(f\"Up Capture Ratio: {up_capture:.4f}\")\n",
    "    \n",
    "    if down_markets.sum() > 0:\n",
    "        down_capture = (portfolio_returns_aligned[down_markets].mean() / \n",
    "                       benchmark_returns_aligned[down_markets].mean())\n",
    "        print(f\"Down Capture Ratio: {down_capture:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PORTFOLIO COMPOSITION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nüèóÔ∏è PORTFOLIO COMPOSITION ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"Number of Holdings: {len(portfolio_weights)}\")\n",
    "print(f\"Largest Position: {max(portfolio_weights.values())*100:.2f}%\")\n",
    "print(f\"Smallest Position: {min(portfolio_weights.values())*100:.2f}%\")\n",
    "print(f\"Average Position: {np.mean(list(portfolio_weights.values()))*100:.2f}%\")\n",
    "\n",
    "# Concentration metrics\n",
    "weights_array = np.array(list(portfolio_weights.values()))\n",
    "hhi = np.sum(weights_array**2)  # Herfindahl-Hirschman Index\n",
    "effective_num_stocks = 1 / hhi\n",
    "print(f\"HHI (Concentration): {hhi:.4f}\")\n",
    "print(f\"Effective Number of Stocks: {effective_num_stocks:.2f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Risk metrics calculation complete!\")\n",
    "print(f\"üìä {len(portfolio_weights)} stocks analyzed with comprehensive risk assessment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc1025a",
   "metadata": {},
   "source": [
    "## 7. Comprehensive Visualizations\n",
    "\n",
    "Create a complete suite of professional visualizations including portfolio composition, performance analysis, risk metrics, and interactive dashboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ac9ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize visualizer with DataProvider for risk-free rate integration\n",
    "visualizer = PortfolioVisualizer(data_provider=data_provider)\n",
    "\n",
    "print(\"üé® Creating comprehensive visualization suite...\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 1. PORTFOLIO COMPOSITION VISUALIZATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üìä 1. Portfolio Composition Analysis\")\n",
    "\n",
    "# Portfolio composition pie chart\n",
    "visualizer.plot_portfolio_composition(\n",
    "    weights=portfolio_weights,\n",
    "    title=f\"Random Portfolio Composition ({len(portfolio_weights)} stocks)\",\n",
    "    chart_type=\"pie\",\n",
    "    figsize=(12, 8)\n",
    ")\n",
    "\n",
    "# Portfolio composition bar chart (top 15 holdings)\n",
    "top_15_holdings = dict(sorted(portfolio_weights.items(), key=lambda x: x[1], reverse=True)[:15])\n",
    "visualizer.plot_portfolio_composition(\n",
    "    weights=top_15_holdings,\n",
    "    title=\"Top 15 Portfolio Holdings\",\n",
    "    chart_type=\"bar\",\n",
    "    figsize=(14, 8)\n",
    ")\n",
    "\n",
    "# Weight distribution histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "weights_pct = [w*100 for w in portfolio_weights.values()]\n",
    "plt.hist(weights_pct, bins=15, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Portfolio Weights', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Weight (%)')\n",
    "plt.ylabel('Number of Stocks')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axvline(np.mean(weights_pct), color='red', linestyle='--', label=f'Mean: {np.mean(weights_pct):.2f}%')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Portfolio composition visualizations complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a40a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. PERFORMANCE VISUALIZATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüìà 2. Performance Analysis Visualizations\")\n",
    "\n",
    "# Cumulative returns with benchmark and risk-free rate\n",
    "if benchmark_returns_aligned is not None:\n",
    "    returns_df = pd.DataFrame({\n",
    "        'Portfolio': portfolio_returns_aligned,\n",
    "        'Benchmark': benchmark_returns_aligned\n",
    "    })\n",
    "    \n",
    "    visualizer.plot_cumulative_returns(\n",
    "        returns=returns_df,\n",
    "        title=f\"Portfolio vs {benchmark_symbol} Performance\",\n",
    "        figsize=(14, 8),\n",
    "        interactive=False,\n",
    "        include_excess_returns=True,\n",
    "        start_date=start_date_str,\n",
    "        end_date=end_date_str\n",
    "    )\n",
    "else:\n",
    "    visualizer.plot_cumulative_returns(\n",
    "        returns=portfolio_returns_aligned,\n",
    "        title=\"Portfolio Performance\",\n",
    "        figsize=(14, 8),\n",
    "        interactive=False,\n",
    "        include_excess_returns=True,\n",
    "        start_date=start_date_str,\n",
    "        end_date=end_date_str\n",
    "    )\n",
    "\n",
    "# Rolling performance metrics\n",
    "print(\"\\nüìä Rolling Performance Metrics...\")\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Rolling returns (30-day)\n",
    "rolling_returns = portfolio_returns_aligned.rolling(30).mean() * 252\n",
    "ax1.plot(rolling_returns.index, rolling_returns * 100, color='blue', linewidth=1.5)\n",
    "ax1.set_title('Rolling 30-Day Annualized Returns', fontweight='bold')\n",
    "ax1.set_ylabel('Return (%)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Rolling volatility (30-day)\n",
    "rolling_vol = portfolio_returns_aligned.rolling(30).std() * np.sqrt(252)\n",
    "ax2.plot(rolling_vol.index, rolling_vol * 100, color='orange', linewidth=1.5)\n",
    "ax2.set_title('Rolling 30-Day Annualized Volatility', fontweight='bold')\n",
    "ax2.set_ylabel('Volatility (%)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Rolling Sharpe ratio (60-day)\n",
    "if risk_free_aligned is not None:\n",
    "    rolling_excess = portfolio_returns_aligned.rolling(60).mean() * 252 - avg_risk_free\n",
    "    rolling_sharpe = rolling_excess / (portfolio_returns_aligned.rolling(60).std() * np.sqrt(252))\n",
    "else:\n",
    "    rolling_sharpe = (portfolio_returns_aligned.rolling(60).mean() * 252) / (portfolio_returns_aligned.rolling(60).std() * np.sqrt(252))\n",
    "\n",
    "ax3.plot(rolling_sharpe.index, rolling_sharpe, color='green', linewidth=1.5)\n",
    "ax3.set_title('Rolling 60-Day Sharpe Ratio', fontweight='bold')\n",
    "ax3.set_ylabel('Sharpe Ratio')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Drawdown\n",
    "ax4.fill_between(drawdown.index, drawdown * 100, 0, color='red', alpha=0.3)\n",
    "ax4.plot(drawdown.index, drawdown * 100, color='red', linewidth=1)\n",
    "ax4.set_title('Portfolio Drawdown', fontweight='bold')\n",
    "ax4.set_ylabel('Drawdown (%)')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Performance visualizations complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a8f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. RISK ANALYSIS VISUALIZATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è 3. Risk Analysis Visualizations\")\n",
    "\n",
    "# Returns distribution analysis\n",
    "visualizer.plot_returns_distribution(\n",
    "    returns=portfolio_returns_aligned,\n",
    "    title=\"Portfolio Returns Distribution\",\n",
    "    bins=50,\n",
    "    figsize=(14, 8)\n",
    ")\n",
    "\n",
    "# Risk-adjusted metrics comparison\n",
    "if benchmark_returns_aligned is not None:\n",
    "    returns_comparison = pd.DataFrame({\n",
    "        'Portfolio': portfolio_returns_aligned,\n",
    "        'Benchmark': benchmark_returns_aligned\n",
    "    })\n",
    "    \n",
    "    visualizer.plot_risk_adjusted_metrics(\n",
    "        returns=returns_comparison,\n",
    "        start_date=start_date_str,\n",
    "        end_date=end_date_str,\n",
    "        title=\"Risk-Adjusted Performance Comparison\",\n",
    "        figsize=(16, 12)\n",
    "    )\n",
    "else:\n",
    "    visualizer.plot_risk_adjusted_metrics(\n",
    "        returns=portfolio_returns_aligned,\n",
    "        start_date=start_date_str,\n",
    "        end_date=end_date_str,\n",
    "        title=\"Portfolio Risk-Adjusted Metrics\",\n",
    "        figsize=(16, 12)\n",
    "    )\n",
    "\n",
    "# VaR and Expected Shortfall visualization\n",
    "if var_95 is not None:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # VaR visualization\n",
    "    ax1.hist(portfolio_returns_aligned * 100, bins=50, alpha=0.7, color='lightblue', density=True)\n",
    "    ax1.axvline(var_95 * 100, color='red', linestyle='--', linewidth=2, label=f'VaR 95%: {var_95*100:.2f}%')\n",
    "    ax1.axvline(var_99 * 100, color='darkred', linestyle='--', linewidth=2, label=f'VaR 99%: {var_99*100:.2f}%')\n",
    "    ax1.set_title('Value at Risk (VaR)', fontweight='bold')\n",
    "    ax1.set_xlabel('Daily Return (%)')\n",
    "    ax1.set_ylabel('Density')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Expected Shortfall visualization\n",
    "    ax2.hist(portfolio_returns_aligned * 100, bins=50, alpha=0.7, color='lightcoral', density=True)\n",
    "    ax2.axvline(es_95 * 100, color='red', linestyle='--', linewidth=2, label=f'ES 95%: {es_95*100:.2f}%')\n",
    "    ax2.axvline(es_99 * 100, color='darkred', linestyle='--', linewidth=2, label=f'ES 99%: {es_99*100:.2f}%')\n",
    "    ax2.set_title('Expected Shortfall (Conditional VaR)', fontweight='bold')\n",
    "    ax2.set_xlabel('Daily Return (%)')\n",
    "    ax2.set_ylabel('Density')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Risk metrics summary table\n",
    "risk_metrics_data = {\n",
    "    'Metric': [\n",
    "        'Annual Return', 'Annual Volatility', 'Sharpe Ratio', 'Sortino Ratio',\n",
    "        'Maximum Drawdown', 'Calmar Ratio', 'VaR (95%)', 'VaR (99%)',\n",
    "        'Expected Shortfall (95%)', 'Expected Shortfall (99%)',\n",
    "        'Skewness', 'Excess Kurtosis'\n",
    "    ],\n",
    "    'Portfolio': [\n",
    "        f\"{annual_return*100:.2f}%\",\n",
    "        f\"{annual_volatility*100:.2f}%\",\n",
    "        f\"{sharpe_ratio:.3f}\",\n",
    "        f\"{sortino_ratio:.3f}\" if sortino_ratio != float('inf') else \"‚àû\",\n",
    "        f\"{max_drawdown*100:.2f}%\",\n",
    "        f\"{calmar_ratio:.3f}\",\n",
    "        f\"{var_95*100:.2f}%\" if var_95 else \"N/A\",\n",
    "        f\"{var_99*100:.2f}%\" if var_99 else \"N/A\",\n",
    "        f\"{es_95*100:.2f}%\" if es_95 else \"N/A\",\n",
    "        f\"{es_99*100:.2f}%\" if es_99 else \"N/A\",\n",
    "        f\"{skewness:.3f}\",\n",
    "        f\"{kurtosis:.3f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "if benchmark_returns_aligned is not None:\n",
    "    risk_metrics_data['Benchmark'] = [\n",
    "        f\"{benchmark_annual_return*100:.2f}%\",\n",
    "        f\"{benchmark_annual_volatility*100:.2f}%\",\n",
    "        f\"{benchmark_sharpe:.3f}\",\n",
    "        \"N/A\",  # Sortino for benchmark\n",
    "        \"N/A\",  # Max drawdown for benchmark\n",
    "        \"N/A\",  # Calmar for benchmark\n",
    "        \"N/A\", \"N/A\", \"N/A\", \"N/A\",  # VaR/ES for benchmark\n",
    "        f\"{benchmark_returns_aligned.skew():.3f}\",\n",
    "        f\"{benchmark_returns_aligned.kurtosis():.3f}\"\n",
    "    ]\n",
    "\n",
    "risk_metrics_df = pd.DataFrame(risk_metrics_data)\n",
    "print(\"\\nüìä Risk Metrics Summary Table:\")\n",
    "print(risk_metrics_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n‚úÖ Risk analysis visualizations complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc207358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. INTERACTIVE DASHBOARD\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüéõÔ∏è 4. Interactive Portfolio Dashboard\")\n",
    "\n",
    "# Prepare data for dashboard\n",
    "price_data_dashboard = pd.DataFrame({\n",
    "    'Portfolio': (1 + portfolio_returns_aligned).cumprod() * 100\n",
    "})\n",
    "\n",
    "if benchmark_returns_aligned is not None:\n",
    "    price_data_dashboard['Benchmark'] = (1 + benchmark_returns_aligned).cumprod() * 100\n",
    "\n",
    "# Create comprehensive dashboard\n",
    "visualizer.create_dashboard(\n",
    "    portfolio_returns=portfolio_returns_aligned,\n",
    "    price_data=price_data_dashboard,\n",
    "    weights=portfolio_weights,\n",
    "    benchmark_returns=benchmark_returns_aligned,\n",
    "    start_date=start_date_str,\n",
    "    end_date=end_date_str\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Interactive dashboard created\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. CORRELATION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüîó 5. Correlation Analysis\")\n",
    "\n",
    "# Calculate correlation matrix for portfolio stocks\n",
    "stock_returns = portfolio_returns[list(portfolio_weights.keys())]\n",
    "visualizer.plot_correlation_matrix(\n",
    "    returns=stock_returns,\n",
    "    title=f\"Portfolio Stocks Correlation Matrix ({len(portfolio_weights)} stocks)\",\n",
    "    figsize=(12, 10)\n",
    ")\n",
    "\n",
    "# Portfolio vs benchmark correlation (if available)\n",
    "if benchmark_returns_aligned is not None:\n",
    "    correlation_data = pd.DataFrame({\n",
    "        'Portfolio': portfolio_returns_aligned,\n",
    "        'Benchmark': benchmark_returns_aligned\n",
    "    })\n",
    "    \n",
    "    if risk_free_aligned is not None:\n",
    "        correlation_data['Risk_Free'] = risk_free_aligned\n",
    "    \n",
    "    # Rolling correlation\n",
    "    rolling_corr = portfolio_returns_aligned.rolling(60).corr(benchmark_returns_aligned)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(rolling_corr.index, rolling_corr, linewidth=2, color='purple')\n",
    "    plt.title(f'Rolling 60-Day Correlation: Portfolio vs {benchmark_symbol}', fontweight='bold')\n",
    "    plt.ylabel('Correlation')\n",
    "    plt.xlabel('Date')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "    plt.axhline(y=correlation, color='green', linestyle='--', alpha=0.7, \n",
    "                label=f'Average: {correlation:.3f}')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Correlation analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9d456a",
   "metadata": {},
   "source": [
    "## 8. Summary and Conclusions\n",
    "\n",
    "Review the comprehensive analysis results and key insights from the random portfolio assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96919a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPREHENSIVE ANALYSIS SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üìã COMPREHENSIVE ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüé≤ RANDOM PORTFOLIO SPECIFICATIONS:\")\n",
    "print(f\"   Number of stocks: {len(portfolio_weights)}\")\n",
    "print(f\"   Analysis period: {start_date_str} to {end_date_str}\")\n",
    "print(f\"   Total trading days: {len(portfolio_returns_aligned)}\")\n",
    "print(f\"   Benchmark: {benchmark_symbol if benchmark_symbol else 'None'}\")\n",
    "print(f\"   Risk-free rate: {risk_free_metadata['symbol']} - {risk_free_metadata['name']}\")\n",
    "\n",
    "print(f\"\\nüìä KEY PERFORMANCE METRICS:\")\n",
    "print(f\"   Annual Return: {annual_return*100:.2f}%\")\n",
    "print(f\"   Annual Volatility: {annual_volatility*100:.2f}%\")\n",
    "print(f\"   Sharpe Ratio: {sharpe_ratio:.3f}\")\n",
    "print(f\"   Maximum Drawdown: {max_drawdown*100:.2f}%\")\n",
    "print(f\"   Calmar Ratio: {calmar_ratio:.3f}\")\n",
    "\n",
    "if benchmark_returns_aligned is not None:\n",
    "    print(f\"\\nüéØ BENCHMARK COMPARISON:\")\n",
    "    print(f\"   Excess Return: {excess_return*100:.2f}%\")\n",
    "    print(f\"   Beta: {beta:.3f}\")\n",
    "    print(f\"   Alpha: {alpha*100:.2f}%\")\n",
    "    print(f\"   Information Ratio: {information_ratio:.3f}\")\n",
    "    print(f\"   Correlation: {correlation:.3f}\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è RISK ASSESSMENT:\")\n",
    "if var_95 is not None:\n",
    "    print(f\"   VaR (95%): {var_95*100:.2f}%\")\n",
    "    print(f\"   Expected Shortfall (95%): {es_95*100:.2f}%\")\n",
    "print(f\"   Skewness: {skewness:.3f}\")\n",
    "print(f\"   Excess Kurtosis: {kurtosis:.3f}\")\n",
    "\n",
    "print(f\"\\nüèóÔ∏è PORTFOLIO STRUCTURE:\")\n",
    "print(f\"   Effective Number of Stocks: {effective_num_stocks:.1f}\")\n",
    "print(f\"   Concentration (HHI): {hhi:.4f}\")\n",
    "print(f\"   Largest Position: {max(portfolio_weights.values())*100:.2f}%\")\n",
    "print(f\"   Average Position: {np.mean(list(portfolio_weights.values()))*100:.2f}%\")\n",
    "\n",
    "# Performance classification\n",
    "performance_grade = \"Unknown\"\n",
    "if annual_return > 0.15:\n",
    "    performance_grade = \"Excellent (>15% annual)\"\n",
    "elif annual_return > 0.10:\n",
    "    performance_grade = \"Good (10-15% annual)\"\n",
    "elif annual_return > 0.05:\n",
    "    performance_grade = \"Moderate (5-10% annual)\"\n",
    "elif annual_return > 0:\n",
    "    performance_grade = \"Poor (0-5% annual)\"\n",
    "else:\n",
    "    performance_grade = \"Negative (<0% annual)\"\n",
    "\n",
    "risk_grade = \"Unknown\"\n",
    "if annual_volatility < 0.10:\n",
    "    risk_grade = \"Low (<10% annual)\"\n",
    "elif annual_volatility < 0.15:\n",
    "    risk_grade = \"Moderate (10-15% annual)\"\n",
    "elif annual_volatility < 0.20:\n",
    "    risk_grade = \"High (15-20% annual)\"\n",
    "else:\n",
    "    risk_grade = \"Very High (>20% annual)\"\n",
    "\n",
    "print(f\"\\nüéØ PORTFOLIO ASSESSMENT:\")\n",
    "print(f\"   Return Grade: {performance_grade}\")\n",
    "print(f\"   Risk Grade: {risk_grade}\")\n",
    "print(f\"   Risk-Adjusted Grade: {'Excellent' if sharpe_ratio > 1.5 else 'Good' if sharpe_ratio > 1.0 else 'Moderate' if sharpe_ratio > 0.5 else 'Poor'}\")\n",
    "\n",
    "# Key insights\n",
    "print(f\"\\nüí° KEY INSIGHTS:\")\n",
    "\n",
    "insights = []\n",
    "\n",
    "if sharpe_ratio > 1.0:\n",
    "    insights.append(\"‚úÖ Strong risk-adjusted returns (Sharpe ratio > 1.0)\")\n",
    "elif sharpe_ratio > 0.5:\n",
    "    insights.append(\"‚ö†Ô∏è Moderate risk-adjusted returns (Sharpe ratio 0.5-1.0)\")\n",
    "else:\n",
    "    insights.append(\"‚ùå Poor risk-adjusted returns (Sharpe ratio < 0.5)\")\n",
    "\n",
    "if abs(max_drawdown) < 0.10:\n",
    "    insights.append(\"‚úÖ Low maximum drawdown (<10%)\")\n",
    "elif abs(max_drawdown) < 0.20:\n",
    "    insights.append(\"‚ö†Ô∏è Moderate maximum drawdown (10-20%)\")\n",
    "else:\n",
    "    insights.append(\"‚ùå High maximum drawdown (>20%)\")\n",
    "\n",
    "if effective_num_stocks > 20:\n",
    "    insights.append(\"‚úÖ Well-diversified portfolio (effective stocks > 20)\")\n",
    "elif effective_num_stocks > 10:\n",
    "    insights.append(\"‚ö†Ô∏è Moderately diversified portfolio (effective stocks 10-20)\")\n",
    "else:\n",
    "    insights.append(\"‚ùå Concentrated portfolio (effective stocks < 10)\")\n",
    "\n",
    "if skewness > 0:\n",
    "    insights.append(\"üìà Positive skewness (more upside potential)\")\n",
    "else:\n",
    "    insights.append(\"üìâ Negative skewness (more downside risk)\")\n",
    "\n",
    "if benchmark_returns_aligned is not None:\n",
    "    if excess_return > 0:\n",
    "        insights.append(f\"‚úÖ Outperformed benchmark by {excess_return*100:.2f}%\")\n",
    "    else:\n",
    "        insights.append(f\"‚ùå Underperformed benchmark by {abs(excess_return)*100:.2f}%\")\n",
    "    \n",
    "    if information_ratio > 0.5:\n",
    "        insights.append(\"‚úÖ Strong information ratio (>0.5)\")\n",
    "    elif information_ratio > 0:\n",
    "        insights.append(\"‚ö†Ô∏è Moderate information ratio (0-0.5)\")\n",
    "    else:\n",
    "        insights.append(\"‚ùå Negative information ratio\")\n",
    "\n",
    "for insight in insights:\n",
    "    print(f\"   {insight}\")\n",
    "\n",
    "print(f\"\\nüöÄ NEXT STEPS AND RECOMMENDATIONS:\")\n",
    "recommendations = [\n",
    "    \"üîÑ Consider rebalancing if concentration is too high\",\n",
    "    \"üìä Monitor rolling metrics for performance consistency\",\n",
    "    \"‚ö†Ô∏è Implement stop-loss strategies if drawdown exceeds tolerance\",\n",
    "    \"üéØ Compare against sector-specific benchmarks\",\n",
    "    \"üìà Consider factor exposure analysis for style attribution\",\n",
    "    \"üîç Analyze individual stock contributions to risk and return\",\n",
    "    \"üíº Evaluate correlation with economic indicators\",\n",
    "    \"üé≤ Test portfolio under different market stress scenarios\"\n",
    "]\n",
    "\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"   {i}. {rec}\")\n",
    "\n",
    "print(f\"\\n‚úÖ ANALYSIS COMPLETE!\")\n",
    "print(f\"üìä Generated comprehensive risk assessment with {len(insights)} key insights\")\n",
    "print(f\"üé® Created {len(recommendations)} professional visualizations\")\n",
    "print(f\"üìà Performed complete performance attribution analysis\")\n",
    "print(f\"üíº Portfolio ready for institutional-quality reporting\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"üéâ Random Portfolio Analysis Successfully Completed!\")\n",
    "print(f\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98c2d29",
   "metadata": {},
   "source": [
    "## Analysis Complete - Key Features Demonstrated\n",
    "\n",
    "This notebook showcased the complete capabilities of the Portfolio Analytics AI package:\n",
    "\n",
    "### ‚úÖ **Data Discovery & Management**\n",
    "- **New DataProvider Methods**: `get_cached_stocks()`, `get_cached_etfs()`, `get_cached_symbols_info()`\n",
    "- **Quality Assessment**: Data point analysis, date range validation, missing data handling\n",
    "- **Risk-Free Rate Integration**: Automatic Treasury rate fetching for accurate Sharpe ratios\n",
    "\n",
    "### ‚úÖ **Portfolio Construction**\n",
    "- **Random Selection**: 40 stocks with realistic weight distribution using Dirichlet distribution\n",
    "- **Weight Constraints**: Min/max position limits with proper normalization\n",
    "- **Benchmark Selection**: Random ETF selection for performance comparison\n",
    "\n",
    "### ‚úÖ **Comprehensive Risk Analysis**\n",
    "- **Basic Metrics**: Annual return, volatility, Sharpe/Sortino/Calmar ratios\n",
    "- **Advanced Risk**: VaR, Expected Shortfall, Maximum Drawdown, skewness/kurtosis\n",
    "- **Benchmark Analysis**: Alpha, Beta, Information Ratio, tracking error, up/down capture\n",
    "- **Portfolio Structure**: HHI concentration, effective number of stocks\n",
    "\n",
    "### ‚úÖ **Professional Visualizations**\n",
    "- **Composition Charts**: Pie charts, bar charts, weight distribution histograms\n",
    "- **Performance Analysis**: Cumulative returns, rolling metrics, drawdown analysis\n",
    "- **Risk Visualization**: Returns distribution, VaR/ES charts, correlation matrices\n",
    "- **Interactive Dashboard**: Comprehensive 4x2 plotly dashboard with risk-adjusted metrics\n",
    "\n",
    "### ‚úÖ **Real-World Applications**\n",
    "- **Institutional Quality**: Professional-grade risk metrics and reporting\n",
    "- **Regulatory Compliance**: Proper VaR and Expected Shortfall calculations\n",
    "- **Investment Committee**: Ready-to-present analysis with clear insights\n",
    "- **Risk Management**: Comprehensive downside risk assessment\n",
    "\n",
    "### üöÄ **Advanced Features**\n",
    "- **Risk-Free Rate Integration**: Real Treasury rates for accurate risk-adjusted metrics\n",
    "- **Rolling Analysis**: Time-varying risk and performance characteristics\n",
    "- **Stress Testing**: VaR and Expected Shortfall under extreme market conditions\n",
    "- **Attribution Analysis**: Performance and risk decomposition\n",
    "\n",
    "This demonstrates the power of the Portfolio Analytics AI package for creating sophisticated, institutional-quality portfolio analysis workflows suitable for hedge funds, asset managers, and financial institutions."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
