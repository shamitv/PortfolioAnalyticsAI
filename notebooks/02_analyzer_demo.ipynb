{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e5dfb7",
   "metadata": {},
   "source": [
    "# Portfolio Analyzer for Vision-Capable LLMs\n",
    "\n",
    "This notebook demonstrates the comprehensive **Analyzer** class that generates metrics, Greeks, and visualizations specifically designed for Vision-Capable LLM analysis.\n",
    "\n",
    "## 🎯 What the Analyzer Does\n",
    "\n",
    "The `Analyzer` class takes a `Portfolio` object and generates:\n",
    "1. **Comprehensive Metrics** - Performance, risk, allocation, and time-based analysis\n",
    "2. **Portfolio Greeks** - Delta, Gamma, Theta, Vega, Rho calculations\n",
    "3. **LLM-Ready Visualizations** - Base64 encoded images optimized for vision models\n",
    "\n",
    "All outputs are structured in JSON format for easy LLM consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2500b2a6",
   "metadata": {},
   "source": [
    "## 📦 Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab4c428f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All imports successful!\n",
      "📅 Analysis Date: 2025-07-26 17:10:58\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add the src directory to the path to import our package\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our portfolio analytics package\n",
    "from portfolio_analytics import Portfolio, DataProvider, Analyzer\n",
    "\n",
    "print(\"✅ All imports successful!\")\n",
    "print(f\"📅 Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbfb0ad",
   "metadata": {},
   "source": [
    "## 🏗️ Create Sample Portfolio\n",
    "\n",
    "Let's create a technology-focused portfolio for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3df78a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Created Portfolio: Tech Growth Portfolio\n",
      "🏢 Assets: AAPL, GOOGL, MSFT, AMZN, TSLA\n",
      "⚖️ Weights: ['30.0%', '25.0%', '20.0%', '15.0%', '10.0%']\n",
      "✅ Weights sum to: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Define portfolio components\n",
    "symbols = ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'TSLA']\n",
    "weights = [0.30, 0.25, 0.20, 0.15, 0.10]  # Strategic allocation\n",
    "portfolio_name = \"Tech Growth Portfolio\"\n",
    "\n",
    "# Create portfolio object\n",
    "portfolio = Portfolio(\n",
    "    symbols=symbols, \n",
    "    weights=weights, \n",
    "    name=portfolio_name\n",
    ")\n",
    "\n",
    "print(f\"📊 Created Portfolio: {portfolio_name}\")\n",
    "print(f\"🏢 Assets: {', '.join(symbols)}\")\n",
    "print(f\"⚖️ Weights: {[f'{w:.1%}' for w in weights]}\")\n",
    "print(f\"✅ Weights sum to: {sum(weights):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b339d0e",
   "metadata": {},
   "source": [
    "## 📈 Load Portfolio Data\n",
    "\n",
    "For this demonstration, we'll create synthetic data that mimics real market behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce206ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Generating synthetic market data...\n",
      "📊 Generated 651 trading days of data\n",
      "📅 Period: 2022-01-03 to 2024-07-01\n",
      "💹 Price ranges:\n",
      "  AAPL: $119 - $236 (Final: $178)\n",
      "  GOOGL: $2400 - $4302 (Final: $3369)\n",
      "  MSFT: $247 - $517 (Final: $374)\n",
      "  AMZN: $2986 - $7290 (Final: $6373)\n",
      "  TSLA: $588 - $6662 (Final: $5282)\n"
     ]
    }
   ],
   "source": [
    "# Create synthetic data for demonstration\n",
    "def create_synthetic_portfolio_data(symbols, start_date, end_date, seed=42):\n",
    "    \"\"\"\n",
    "    Create realistic synthetic stock data for demonstration purposes.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Generate date range\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    \n",
    "    # Remove weekends (simulate trading days only)\n",
    "    trading_days = date_range[date_range.weekday < 5]\n",
    "    \n",
    "    # Synthetic parameters for each stock\n",
    "    stock_params = {\n",
    "        'AAPL': {'initial_price': 150, 'drift': 0.08, 'volatility': 0.25},\n",
    "        'GOOGL': {'initial_price': 2800, 'drift': 0.10, 'volatility': 0.28},\n",
    "        'MSFT': {'initial_price': 300, 'drift': 0.09, 'volatility': 0.24},\n",
    "        'AMZN': {'initial_price': 3300, 'drift': 0.12, 'volatility': 0.32},\n",
    "        'TSLA': {'initial_price': 800, 'drift': 0.15, 'volatility': 0.45}\n",
    "    }\n",
    "    \n",
    "    # Generate correlated price data\n",
    "    n_days = len(trading_days)\n",
    "    dt = 1/252  # Daily time step\n",
    "    \n",
    "    # Create correlation matrix (tech stocks are correlated)\n",
    "    correlation_matrix = np.array([\n",
    "        [1.00, 0.70, 0.75, 0.65, 0.50],  # AAPL\n",
    "        [0.70, 1.00, 0.68, 0.72, 0.45],  # GOOGL\n",
    "        [0.75, 0.68, 1.00, 0.70, 0.40],  # MSFT\n",
    "        [0.65, 0.72, 0.70, 1.00, 0.55],  # AMZN\n",
    "        [0.50, 0.45, 0.40, 0.55, 1.00]   # TSLA\n",
    "    ])\n",
    "    \n",
    "    # Generate correlated random shocks\n",
    "    independent_shocks = np.random.normal(0, 1, (n_days, len(symbols)))\n",
    "    \n",
    "    # Apply correlation using Cholesky decomposition\n",
    "    L = np.linalg.cholesky(correlation_matrix)\n",
    "    correlated_shocks = independent_shocks @ L.T\n",
    "    \n",
    "    # Generate price paths\n",
    "    price_data = {}\n",
    "    \n",
    "    for i, symbol in enumerate(symbols):\n",
    "        params = stock_params[symbol]\n",
    "        \n",
    "        # Geometric Brownian Motion\n",
    "        returns = (params['drift'] - 0.5 * params['volatility']**2) * dt + \\\n",
    "                 params['volatility'] * np.sqrt(dt) * correlated_shocks[:, i]\n",
    "        \n",
    "        # Add some market regime changes and volatility clustering\n",
    "        # Market crash simulation (rare events)\n",
    "        crash_prob = 0.002  # 0.2% daily probability\n",
    "        crash_events = np.random.random(n_days) < crash_prob\n",
    "        returns[crash_events] += np.random.normal(-0.05, 0.02, crash_events.sum())\n",
    "        \n",
    "        # Volatility clustering (GARCH-like)\n",
    "        for j in range(1, len(returns)):\n",
    "            if abs(returns[j-1]) > 0.03:  # Previous day was volatile\n",
    "                returns[j] *= 1.5  # Increase today's volatility\n",
    "        \n",
    "        # Calculate cumulative prices\n",
    "        prices = params['initial_price'] * np.exp(np.cumsum(returns))\n",
    "        price_data[symbol] = prices\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(price_data, index=trading_days)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate synthetic data\n",
    "start_date = \"2022-01-01\"\n",
    "end_date = \"2024-07-01\"\n",
    "\n",
    "print(\"🔄 Generating synthetic market data...\")\n",
    "synthetic_data = create_synthetic_portfolio_data(symbols, start_date, end_date)\n",
    "\n",
    "# Manually set the data and calculate returns (since we're using synthetic data)\n",
    "portfolio.data = synthetic_data\n",
    "portfolio.returns = portfolio.data.pct_change().dropna()\n",
    "\n",
    "print(f\"📊 Generated {len(portfolio.data)} trading days of data\")\n",
    "print(f\"📅 Period: {portfolio.data.index.min().date()} to {portfolio.data.index.max().date()}\")\n",
    "print(f\"💹 Price ranges:\")\n",
    "for symbol in symbols:\n",
    "    min_price = portfolio.data[symbol].min()\n",
    "    max_price = portfolio.data[symbol].max()\n",
    "    final_price = portfolio.data[symbol].iloc[-1]\n",
    "    print(f\"  {symbol}: ${min_price:.0f} - ${max_price:.0f} (Final: ${final_price:.0f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626f7fb9",
   "metadata": {},
   "source": [
    "## 🔍 Initialize the Analyzer\n",
    "\n",
    "Now let's create the Analyzer object and see what it can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b977e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 Portfolio Analyzer initialized!\n",
      "📊 Analyzing portfolio: Tech Growth Portfolio\n",
      "🏢 Assets under analysis: 5\n",
      "📈 Data points: 650 daily returns\n",
      "\n",
      "🛠️ Analyzer Capabilities:\n",
      "  ✅ Performance Metrics (Returns, Sharpe, Sortino, etc.)\n",
      "  ✅ Risk Metrics (VaR, Expected Shortfall, Drawdowns)\n",
      "  ✅ Portfolio Greeks (Delta, Gamma, Theta, Vega, Rho)\n",
      "  ✅ Asset-level Analysis\n",
      "  ✅ Time-based Performance Analysis\n",
      "  ✅ Stress Testing & Sensitivity Analysis\n",
      "  ✅ 10+ Visualization Charts (Base64 Encoded)\n",
      "  ✅ LLM-optimized JSON Output\n"
     ]
    }
   ],
   "source": [
    "# Create the Analyzer\n",
    "analyzer = Analyzer(portfolio)\n",
    "\n",
    "print(\"🔬 Portfolio Analyzer initialized!\")\n",
    "print(f\"📊 Analyzing portfolio: {portfolio.name}\")\n",
    "print(f\"🏢 Assets under analysis: {len(portfolio.symbols)}\")\n",
    "print(f\"📈 Data points: {len(portfolio.returns)} daily returns\")\n",
    "\n",
    "# Show the analyzer's capabilities\n",
    "print(\"\\n🛠️ Analyzer Capabilities:\")\n",
    "capabilities = [\n",
    "    \"✅ Performance Metrics (Returns, Sharpe, Sortino, etc.)\",\n",
    "    \"✅ Risk Metrics (VaR, Expected Shortfall, Drawdowns)\", \n",
    "    \"✅ Portfolio Greeks (Delta, Gamma, Theta, Vega, Rho)\",\n",
    "    \"✅ Asset-level Analysis\",\n",
    "    \"✅ Time-based Performance Analysis\",\n",
    "    \"✅ Stress Testing & Sensitivity Analysis\",\n",
    "    \"✅ 10+ Visualization Charts (Base64 Encoded)\",\n",
    "    \"✅ LLM-optimized JSON Output\"\n",
    "]\n",
    "\n",
    "for capability in capabilities:\n",
    "    print(f\"  {capability}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ecd89a",
   "metadata": {},
   "source": [
    "## 📊 Generate Comprehensive Analysis\n",
    "\n",
    "Let's run the full analysis and see all the metrics and Greeks generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9cacbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Running comprehensive portfolio analysis...\n",
      "This includes: Metrics + Greeks + Visualizations\n",
      "\n",
      "✅ Analysis Complete!\n",
      "📦 Generated 4 main sections:\n",
      "  📋 metrics\n",
      "  📋 greeks\n",
      "  📋 visualizations\n",
      "  📋 portfolio_summary\n",
      "\n",
      "📊 Metrics Categories:\n",
      "  • performance: 16 metrics\n",
      "  • risk: 15 metrics\n",
      "  • portfolio: 6 metrics\n",
      "  • allocation: 6 metrics\n",
      "  • time_based: 3 metrics\n",
      "  • summary_statistics: 9 metrics\n",
      "\n",
      "🔢 Greeks Categories:\n",
      "  • portfolio_greeks: 5 calculations\n",
      "  • asset_greeks: 5 calculations\n",
      "  • sensitivity_analysis: 3 calculations\n",
      "\n",
      "📈 Visualizations Generated:\n",
      "  🖼️ price_history\n",
      "  🖼️ returns_distribution\n",
      "  🖼️ correlation_matrix\n",
      "  🖼️ portfolio_composition\n",
      "  🖼️ cumulative_returns\n",
      "  🖼️ drawdown_analysis\n",
      "  🖼️ risk_return_scatter\n",
      "  🖼️ rolling_metrics\n",
      "  🖼️ performance_heatmap\n",
      "  🖼️ greek_sensitivity\n"
     ]
    }
   ],
   "source": [
    "# Generate comprehensive analysis\n",
    "print(\"🔄 Running comprehensive portfolio analysis...\")\n",
    "print(\"This includes: Metrics + Greeks + Visualizations\")\n",
    "\n",
    "# Run the analysis\n",
    "analysis_results = analyzer.export_for_llm(output_format=\"comprehensive\")\n",
    "\n",
    "print(\"\\n✅ Analysis Complete!\")\n",
    "print(f\"📦 Generated {len(analysis_results)} main sections:\")\n",
    "for section_name in analysis_results.keys():\n",
    "    print(f\"  📋 {section_name}\")\n",
    "\n",
    "# Show the structure\n",
    "print(\"\\n📊 Metrics Categories:\")\n",
    "for category in analysis_results['metrics'].keys():\n",
    "    count = len(analysis_results['metrics'][category])\n",
    "    print(f\"  • {category}: {count} metrics\")\n",
    "\n",
    "print(\"\\n🔢 Greeks Categories:\")\n",
    "for category in analysis_results['greeks'].keys():\n",
    "    if isinstance(analysis_results['greeks'][category], dict):\n",
    "        count = len(analysis_results['greeks'][category])\n",
    "        print(f\"  • {category}: {count} calculations\")\n",
    "\n",
    "print(\"\\n📈 Visualizations Generated:\")\n",
    "for viz_name in analysis_results['visualizations'].keys():\n",
    "    print(f\"  🖼️ {viz_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e391ab",
   "metadata": {},
   "source": [
    "## 📈 Portfolio Performance Summary\n",
    "\n",
    "Let's examine the key performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9432c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 PORTFOLIO PERFORMANCE SUMMARY\n",
      "==================================================\n",
      "\n",
      "🏢 Portfolio: Tech Growth Portfolio\n",
      "📅 Analysis Period: 2022-01-03 to 2024-07-01\n",
      "📊 Total Observations: 650 trading days\n",
      "\n",
      "💰 RETURN METRICS:\n",
      "  📈 Total Return: 59.59%\n",
      "  📊 Annual Return: 21.48%\n",
      "  📊 Average Monthly Return: 1.79%\n",
      "  🚀 Best Month: 18.90%\n",
      "  📉 Worst Month: -12.24%\n",
      "  ✅ Positive Months: 18\n",
      "  ❌ Negative Months: 13\n",
      "\n",
      "⚠️ RISK METRICS:\n",
      "  📊 Annual Volatility: 25.93%\n",
      "  📉 Maximum Drawdown: 20.89%\n",
      "  📊 VaR (95%): 2.62%\n",
      "  📊 Expected Shortfall (95%): 3.26%\n",
      "  📊 Skewness: 0.062\n",
      "  📊 Kurtosis: 0.351\n",
      "\n",
      "🎯 RISK-ADJUSTED METRICS:\n",
      "  ⭐ Sharpe Ratio: 0.751\n",
      "  📊 Sortino Ratio: 1.234\n",
      "  📊 Calmar Ratio: 1.028\n",
      "\n",
      "⚖️ PORTFOLIO COMPOSITION:\n",
      "  🏢 AAPL: 30.0%\n",
      "  🏢 GOOGL: 25.0%\n",
      "  🏢 MSFT: 20.0%\n",
      "  🏢 AMZN: 15.0%\n",
      "  🏢 TSLA: 10.0%\n",
      "\n",
      "📊 PORTFOLIO STRUCTURE:\n",
      "  🎯 Concentration (HHI): 0.225\n",
      "  📊 Largest Position: 30.0%\n",
      "  🔢 Effective # of Assets: 4.4\n",
      "  🏢 Positions > 5%: 5\n"
     ]
    }
   ],
   "source": [
    "# Extract key metrics for display\n",
    "portfolio_summary = analysis_results['portfolio_summary']\n",
    "perf_metrics = analysis_results['metrics']['performance']\n",
    "risk_metrics = analysis_results['metrics']['risk']\n",
    "allocation_metrics = analysis_results['metrics']['allocation']\n",
    "\n",
    "print(\"📊 PORTFOLIO PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n🏢 Portfolio: {portfolio_summary['portfolio_name']}\")\n",
    "print(f\"📅 Analysis Period: {portfolio_summary['data_start_date']} to {portfolio_summary['data_end_date']}\")\n",
    "print(f\"📊 Total Observations: {portfolio_summary['total_observations']:,} trading days\")\n",
    "\n",
    "print(\"\\n💰 RETURN METRICS:\")\n",
    "print(f\"  📈 Total Return: {perf_metrics.get('total_return', 0):.2%}\")\n",
    "print(f\"  📊 Annual Return: {perf_metrics.get('annual_return', 0):.2%}\")\n",
    "print(f\"  📊 Average Monthly Return: {perf_metrics.get('average_monthly_return', 0):.2%}\")\n",
    "print(f\"  🚀 Best Month: {perf_metrics.get('best_month', 0):.2%}\")\n",
    "print(f\"  📉 Worst Month: {perf_metrics.get('worst_month', 0):.2%}\")\n",
    "print(f\"  ✅ Positive Months: {perf_metrics.get('positive_months', 0)}\")\n",
    "print(f\"  ❌ Negative Months: {perf_metrics.get('negative_months', 0)}\")\n",
    "\n",
    "print(\"\\n⚠️ RISK METRICS:\")\n",
    "print(f\"  📊 Annual Volatility: {perf_metrics.get('annual_volatility', 0):.2%}\")\n",
    "print(f\"  📉 Maximum Drawdown: {perf_metrics.get('max_drawdown', 0):.2%}\")\n",
    "print(f\"  📊 VaR (95%): {risk_metrics.get('var_95', 0):.2%}\")\n",
    "print(f\"  📊 Expected Shortfall (95%): {risk_metrics.get('expected_shortfall_95', 0):.2%}\")\n",
    "print(f\"  📊 Skewness: {risk_metrics.get('skewness', 0):.3f}\")\n",
    "print(f\"  📊 Kurtosis: {risk_metrics.get('kurtosis', 0):.3f}\")\n",
    "\n",
    "print(\"\\n🎯 RISK-ADJUSTED METRICS:\")\n",
    "print(f\"  ⭐ Sharpe Ratio: {perf_metrics.get('sharpe_ratio', 0):.3f}\")\n",
    "print(f\"  📊 Sortino Ratio: {perf_metrics.get('sortino_ratio', 0):.3f}\")\n",
    "print(f\"  📊 Calmar Ratio: {perf_metrics.get('calmar_ratio', 0):.3f}\")\n",
    "\n",
    "print(\"\\n⚖️ PORTFOLIO COMPOSITION:\")\n",
    "for symbol, weight in allocation_metrics['weights'].items():\n",
    "    print(f\"  🏢 {symbol}: {weight:.1%}\")\n",
    "\n",
    "print(f\"\\n📊 PORTFOLIO STRUCTURE:\")\n",
    "print(f\"  🎯 Concentration (HHI): {allocation_metrics['weight_concentration_hhi']:.3f}\")\n",
    "print(f\"  📊 Largest Position: {allocation_metrics['largest_position']:.1%}\")\n",
    "print(f\"  🔢 Effective # of Assets: {analysis_results['metrics']['portfolio']['effective_number_of_assets']:.1f}\")\n",
    "print(f\"  🏢 Positions > 5%: {allocation_metrics['number_positions_over_5pct']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc6d19f",
   "metadata": {},
   "source": [
    "## 🔢 Portfolio Greeks Analysis\n",
    "\n",
    "Let's examine the portfolio Greeks - these measure various sensitivities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62dd3e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔢 PORTFOLIO GREEKS ANALYSIS\n",
      "==================================================\n",
      "\n",
      "📊 PORTFOLIO-LEVEL GREEKS:\n",
      "  📈 Delta (Market Sensitivity): 0.919\n",
      "  🔄 Gamma (Convexity): 2.510\n",
      "  ⏰ Theta (Time Decay): -0.000\n",
      "  🌊 Vega (Vol Sensitivity): -0.057\n",
      "  💰 Rho (Interest Rate Sensitivity): -25.908\n",
      "\n",
      "🏢 ASSET-LEVEL ANALYSIS:\n",
      "Asset      | Weight | Delta  | Beta   | Alpha  | Vol    | Risk Contrib\n",
      "----------------------------------------------------------------------\n",
      "AAPL       | 30.0% |  0.805 |  0.792 | -0.139 | 27.3% |      0.0052\n",
      "GOOGL      | 25.0% |  0.806 |  0.887 | -0.151 | 30.5% |      0.0048\n",
      "MSFT       | 20.0% |  0.807 |  0.737 | -0.109 | 25.4% |      0.0032\n",
      "AMZN       | 15.0% |  0.863 |  1.064 | -0.018 | 34.2% |      0.0032\n",
      "TSLA       | 10.0% |  0.782 |  1.527 |  0.414 | 54.2% |      0.0034\n",
      "\n",
      "📊 INTERPRETATION:\n",
      "• Delta 0.919: Portfolio correlation with market\n",
      "• Gamma 2.510: Rate of change of delta (convexity)\n",
      "• Theta -0.000: Time decay effect on returns\n",
      "• Vega -0.057: Sensitivity to volatility changes\n",
      "• Rho -25.908: Interest rate sensitivity\n"
     ]
    }
   ],
   "source": [
    "# Extract Greeks for analysis\n",
    "portfolio_greeks = analysis_results['greeks']['portfolio_greeks']\n",
    "asset_greeks = analysis_results['greeks']['asset_greeks']\n",
    "\n",
    "print(\"🔢 PORTFOLIO GREEKS ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n📊 PORTFOLIO-LEVEL GREEKS:\")\n",
    "print(f\"  📈 Delta (Market Sensitivity): {portfolio_greeks.get('portfolio_delta', 0):.3f}\")\n",
    "print(f\"  🔄 Gamma (Convexity): {portfolio_greeks.get('portfolio_gamma', 0):.3f}\")\n",
    "print(f\"  ⏰ Theta (Time Decay): {portfolio_greeks.get('portfolio_theta', 0):.3f}\")\n",
    "print(f\"  🌊 Vega (Vol Sensitivity): {portfolio_greeks.get('portfolio_vega', 0):.3f}\")\n",
    "print(f\"  💰 Rho (Interest Rate Sensitivity): {portfolio_greeks.get('portfolio_rho', 0):.3f}\")\n",
    "\n",
    "print(\"\\n🏢 ASSET-LEVEL ANALYSIS:\")\n",
    "print(\"Asset      | Weight | Delta  | Beta   | Alpha  | Vol    | Risk Contrib\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for symbol in symbols:\n",
    "    asset_data = asset_greeks[symbol]\n",
    "    print(f\"{symbol:10} | {asset_data['weight']:5.1%} | {asset_data['delta']:6.3f} | \"\n",
    "          f\"{asset_data['beta']:6.3f} | {asset_data['alpha']:6.3f} | \"\n",
    "          f\"{asset_data['volatility']:5.1%} | {asset_data['contribution_to_risk']:11.4f}\")\n",
    "\n",
    "print(\"\\n📊 INTERPRETATION:\")\n",
    "interpretations = [\n",
    "    f\"• Delta {portfolio_greeks.get('portfolio_delta', 0):.3f}: Portfolio correlation with market\",\n",
    "    f\"• Gamma {portfolio_greeks.get('portfolio_gamma', 0):.3f}: Rate of change of delta (convexity)\",\n",
    "    f\"• Theta {portfolio_greeks.get('portfolio_theta', 0):.3f}: Time decay effect on returns\",\n",
    "    f\"• Vega {portfolio_greeks.get('portfolio_vega', 0):.3f}: Sensitivity to volatility changes\",\n",
    "    f\"• Rho {portfolio_greeks.get('portfolio_rho', 0):.3f}: Interest rate sensitivity\"\n",
    "]\n",
    "\n",
    "for interpretation in interpretations:\n",
    "    print(interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0b3ec7",
   "metadata": {},
   "source": [
    "## 📊 Time-Based Performance Analysis\n",
    "\n",
    "Let's look at how the portfolio performed across different time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6110f9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 TIME-BASED PERFORMANCE ANALYSIS\n",
      "==================================================\n",
      "\n",
      "📊 MONTHLY PERFORMANCE:\n",
      "  📈 Average Monthly Return: 1.79%\n",
      "  📊 Monthly Volatility: 7.59%\n",
      "  🚀 Best Month: 18.90%\n",
      "  📉 Worst Month: -12.24%\n",
      "  ✅ Positive Months: 58.1%\n",
      "  📊 Skewness: 0.583\n",
      "  📊 Kurtosis: -0.041\n",
      "\n",
      "📊 QUARTERLY PERFORMANCE:\n",
      "  📈 Average Quarterly Return: 4.83%\n",
      "  📊 Quarterly Volatility: 10.66%\n",
      "  🚀 Best Quarter: 20.06%\n",
      "  📉 Worst Quarter: -11.23%\n",
      "\n",
      "📊 YEARLY PERFORMANCE:\n",
      "  📈 Average Yearly Return: 18.86%\n",
      "  📊 Yearly Volatility: 25.89%\n",
      "  ✅ Positive Years: 66.7%\n",
      "\n",
      "🎯 PERFORMANCE INSIGHTS:\n",
      "  📊 Monthly Win Rate: 58.1%\n",
      "  📈 Risk-Reward Ratio: 1.54x\n",
      "  📊 Return Consistency: Moderate\n",
      "  📊 Distribution Shape: Skewed\n"
     ]
    }
   ],
   "source": [
    "# Extract time-based metrics\n",
    "time_metrics = analysis_results['metrics']['time_based']\n",
    "\n",
    "print(\"📅 TIME-BASED PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Monthly statistics\n",
    "monthly_stats = time_metrics['monthly_stats']\n",
    "print(\"\\n📊 MONTHLY PERFORMANCE:\")\n",
    "print(f\"  📈 Average Monthly Return: {monthly_stats['mean']:.2%}\")\n",
    "print(f\"  📊 Monthly Volatility: {monthly_stats['std']:.2%}\")\n",
    "print(f\"  🚀 Best Month: {monthly_stats['best_month']:.2%}\")\n",
    "print(f\"  📉 Worst Month: {monthly_stats['worst_month']:.2%}\")\n",
    "print(f\"  ✅ Positive Months: {monthly_stats['positive_months_pct']:.1%}\")\n",
    "print(f\"  📊 Skewness: {monthly_stats['skew']:.3f}\")\n",
    "print(f\"  📊 Kurtosis: {monthly_stats['kurtosis']:.3f}\")\n",
    "\n",
    "# Quarterly statistics\n",
    "quarterly_stats = time_metrics['quarterly_stats']\n",
    "print(\"\\n📊 QUARTERLY PERFORMANCE:\")\n",
    "print(f\"  📈 Average Quarterly Return: {quarterly_stats['mean']:.2%}\")\n",
    "print(f\"  📊 Quarterly Volatility: {quarterly_stats['std']:.2%}\")\n",
    "print(f\"  🚀 Best Quarter: {quarterly_stats['best_quarter']:.2%}\")\n",
    "print(f\"  📉 Worst Quarter: {quarterly_stats['worst_quarter']:.2%}\")\n",
    "\n",
    "# Yearly statistics\n",
    "yearly_stats = time_metrics['yearly_stats']\n",
    "print(\"\\n📊 YEARLY PERFORMANCE:\")\n",
    "print(f\"  📈 Average Yearly Return: {yearly_stats['mean']:.2%}\")\n",
    "print(f\"  📊 Yearly Volatility: {yearly_stats['std']:.2%}\")\n",
    "print(f\"  ✅ Positive Years: {yearly_stats['positive_years_pct']:.1%}\")\n",
    "\n",
    "# Calculate some additional insights\n",
    "win_rate_monthly = monthly_stats['positive_months_pct']\n",
    "avg_win = monthly_stats['best_month'] if monthly_stats['best_month'] > 0 else 0\n",
    "avg_loss = abs(monthly_stats['worst_month']) if monthly_stats['worst_month'] < 0 else 0\n",
    "\n",
    "print(\"\\n🎯 PERFORMANCE INSIGHTS:\")\n",
    "print(f\"  📊 Monthly Win Rate: {win_rate_monthly:.1%}\")\n",
    "print(f\"  📈 Risk-Reward Ratio: {avg_win/avg_loss:.2f}x\" if avg_loss > 0 else \"  📈 Risk-Reward Ratio: N/A\")\n",
    "print(f\"  📊 Return Consistency: {'High' if monthly_stats['std'] < 0.05 else 'Moderate' if monthly_stats['std'] < 0.10 else 'Low'}\")\n",
    "print(f\"  📊 Distribution Shape: {'Normal' if abs(monthly_stats['skew']) < 0.5 else 'Skewed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99741db",
   "metadata": {},
   "source": [
    "## 📈 Visualization Showcase\n",
    "\n",
    "The Analyzer generates multiple charts as base64 encoded images. Let's see what's available and display some key charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86db84fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 VISUALIZATION CAPABILITIES\n",
      "==================================================\n",
      "\n",
      "🖼️ Generated 10 charts for LLM analysis:\n",
      "   1. price_history             (358.3 KB)\n",
      "   2. returns_distribution      (458.8 KB)\n",
      "   3. correlation_matrix        (146.1 KB)\n",
      "   4. portfolio_composition     (199.1 KB)\n",
      "   5. cumulative_returns        (196.3 KB)\n",
      "   6. drawdown_analysis         (386.4 KB)\n",
      "   7. risk_return_scatter       (111.6 KB)\n",
      "   8. rolling_metrics           (658.1 KB)\n",
      "   9. performance_heatmap       (208.8 KB)\n",
      "  10. greek_sensitivity         (268.5 KB)\n",
      "\n",
      "🎯 CHART DESCRIPTIONS:\n",
      "  • 📊 Historical price movements of all assets\n",
      "  • 📈 Distribution analysis with Q-Q plots and volatility\n",
      "  • 🔗 Asset correlation heatmap\n",
      "  • 🥧 Portfolio weights (pie & bar charts)\n",
      "  • 📈 Portfolio performance over time\n",
      "  • 📉 Drawdown periods and recovery analysis\n",
      "  • 🎯 Risk-return positioning of assets\n",
      "  • 📊 Rolling performance metrics over time\n",
      "  • 🌡️ Monthly performance calendar\n",
      "  • 🔢 Greeks and sensitivity analysis\n",
      "\n",
      "✨ All charts are generated as high-resolution, base64-encoded PNG images\n",
      "📤 Ready for direct input to Vision-Capable LLMs\n",
      "💾 Total visualization data: 3.9 MB\n"
     ]
    }
   ],
   "source": [
    "# Show available visualizations\n",
    "visualizations = analysis_results['visualizations']\n",
    "\n",
    "print(\"📈 VISUALIZATION CAPABILITIES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n🖼️ Generated {len(visualizations)} charts for LLM analysis:\")\n",
    "for i, (viz_name, viz_data) in enumerate(visualizations.items(), 1):\n",
    "    # Get the size of the base64 encoded image\n",
    "    size_kb = len(viz_data) * 3 / 4 / 1024  # Approximate size in KB\n",
    "    print(f\"  {i:2d}. {viz_name:25} ({size_kb:.1f} KB)\")\n",
    "\n",
    "print(\"\\n🎯 CHART DESCRIPTIONS:\")\n",
    "descriptions = {\n",
    "    'price_history': '📊 Historical price movements of all assets',\n",
    "    'returns_distribution': '📈 Distribution analysis with Q-Q plots and volatility',\n",
    "    'correlation_matrix': '🔗 Asset correlation heatmap',\n",
    "    'portfolio_composition': '🥧 Portfolio weights (pie & bar charts)',\n",
    "    'cumulative_returns': '📈 Portfolio performance over time',\n",
    "    'drawdown_analysis': '📉 Drawdown periods and recovery analysis',\n",
    "    'risk_return_scatter': '🎯 Risk-return positioning of assets',\n",
    "    'rolling_metrics': '📊 Rolling performance metrics over time',\n",
    "    'performance_heatmap': '🌡️ Monthly performance calendar',\n",
    "    'greek_sensitivity': '🔢 Greeks and sensitivity analysis'\n",
    "}\n",
    "\n",
    "for viz_name, description in descriptions.items():\n",
    "    if viz_name in visualizations:\n",
    "        print(f\"  • {description}\")\n",
    "\n",
    "print(\"\\n✨ All charts are generated as high-resolution, base64-encoded PNG images\")\n",
    "print(\"📤 Ready for direct input to Vision-Capable LLMs\")\n",
    "print(f\"💾 Total visualization data: {sum(len(v) for v in visualizations.values()) / 1024 / 1024:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191f531b",
   "metadata": {},
   "source": [
    "## 🎛️ Different Export Formats\n",
    "\n",
    "The Analyzer supports multiple export formats for different use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7f06f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎛️ EXPORT FORMAT DEMONSTRATION\n",
      "==================================================\n",
      "\n",
      "📦 Testing 'comprehensive' format...\n",
      "  📋 Sections: metrics, greeks, visualizations, portfolio_summary\n",
      "  📊 Data size: 4,092,104 characters\n",
      "  📊 Metrics: 55, Greeks: 13, Charts: 10\n",
      "\n",
      "📦 Testing 'summary' format...\n",
      "  📋 Sections: portfolio_summary, key_metrics, visualizations\n",
      "  📊 Data size: 4,086,208 characters\n",
      "  📊 Key metrics: 8, Charts: 10\n",
      "\n",
      "📦 Testing 'metrics_only' format...\n",
      "  📋 Sections: performance, risk, portfolio, allocation, time_based, summary_statistics\n",
      "  📊 Data size: 3,287 characters\n",
      "  📊 Total metrics: 55\n",
      "\n",
      "📦 Testing 'visuals_only' format...\n",
      "  📋 Sections: price_history, returns_distribution, correlation_matrix, portfolio_composition, cumulative_returns, drawdown_analysis, risk_return_scatter, rolling_metrics, performance_heatmap, greek_sensitivity\n",
      "  📊 Data size: 4,085,405 characters\n",
      "  🖼️ Charts: 10, Avg size: 398.9 KB\n",
      "\n",
      "🎯 USE CASE RECOMMENDATIONS:\n",
      "  📊 'comprehensive' → Full portfolio analysis and reporting\n",
      "  📋 'summary' → Quick portfolio overview with key visuals\n",
      "  🔢 'metrics_only' → Quantitative analysis without charts\n",
      "  🖼️ 'visuals_only' → Chart analysis and pattern recognition\n"
     ]
    }
   ],
   "source": [
    "print(\"🎛️ EXPORT FORMAT DEMONSTRATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test different export formats\n",
    "formats = ['comprehensive', 'summary', 'metrics_only', 'visuals_only']\n",
    "\n",
    "for format_type in formats:\n",
    "    print(f\"\\n📦 Testing '{format_type}' format...\")\n",
    "    export_data = analyzer.export_for_llm(output_format=format_type)\n",
    "    \n",
    "    # Analyze the export\n",
    "    sections = list(export_data.keys())\n",
    "    total_size = len(str(export_data))\n",
    "    \n",
    "    print(f\"  📋 Sections: {', '.join(sections)}\")\n",
    "    print(f\"  📊 Data size: {total_size:,} characters\")\n",
    "    \n",
    "    # Format-specific analysis\n",
    "    if format_type == 'comprehensive':\n",
    "        metrics_count = sum(len(cat) for cat in export_data.get('metrics', {}).values() if isinstance(cat, dict))\n",
    "        greeks_count = sum(len(cat) for cat in export_data.get('greeks', {}).values() if isinstance(cat, dict))\n",
    "        viz_count = len(export_data.get('visualizations', {}))\n",
    "        print(f\"  📊 Metrics: {metrics_count}, Greeks: {greeks_count}, Charts: {viz_count}\")\n",
    "        \n",
    "    elif format_type == 'summary':\n",
    "        key_metrics = export_data.get('key_metrics', {})\n",
    "        viz_count = len(export_data.get('visualizations', {}))\n",
    "        print(f\"  📊 Key metrics: {len(key_metrics)}, Charts: {viz_count}\")\n",
    "        \n",
    "    elif format_type == 'metrics_only':\n",
    "        total_metrics = sum(len(cat) for cat in export_data.values() if isinstance(cat, dict))\n",
    "        print(f\"  📊 Total metrics: {total_metrics}\")\n",
    "        \n",
    "    elif format_type == 'visuals_only':\n",
    "        viz_count = len(export_data)\n",
    "        avg_size = sum(len(v) for v in export_data.values()) / len(export_data) / 1024\n",
    "        print(f\"  🖼️ Charts: {viz_count}, Avg size: {avg_size:.1f} KB\")\n",
    "\n",
    "print(\"\\n🎯 USE CASE RECOMMENDATIONS:\")\n",
    "recommendations = [\n",
    "    \"📊 'comprehensive' → Full portfolio analysis and reporting\",\n",
    "    \"📋 'summary' → Quick portfolio overview with key visuals\", \n",
    "    \"🔢 'metrics_only' → Quantitative analysis without charts\",\n",
    "    \"🖼️ 'visuals_only' → Chart analysis and pattern recognition\"\n",
    "]\n",
    "\n",
    "for rec in recommendations:\n",
    "    print(f\"  {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a9693a",
   "metadata": {},
   "source": [
    "## 🧪 Stress Testing & Sensitivity Analysis\n",
    "\n",
    "The Analyzer includes stress testing capabilities to understand portfolio behavior under different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "763d16aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 STRESS TESTING & SENSITIVITY ANALYSIS\n",
      "==================================================\n",
      "\n",
      "📉 MARKET STRESS SCENARIOS:\n",
      "\n",
      "🔥 Market Crash -10%:\n",
      "  📊 Scenario Return: -2498.52%\n",
      "  📊 Scenario Volatility: 25.93%\n",
      "  📊 VaR (95%): -12.62%\n",
      "  📊 Expected Shortfall: -13.26%\n",
      "\n",
      "💥 Market Crash -20%:\n",
      "  📊 Scenario Return: -5018.52%\n",
      "  📊 Scenario Volatility: 25.93%\n",
      "  📊 VaR (95%): -22.62%\n",
      "  📊 Expected Shortfall: -23.26%\n",
      "\n",
      "🌊 Volatility Spike +50%:\n",
      "  📊 Base Volatility: 25.93%\n",
      "  📊 Stressed Volatility: 38.89%\n",
      "  📊 Volatility Impact: 12.96%\n",
      "\n",
      "🔗 CORRELATION ANALYSIS:\n",
      "  📊 Average Correlation: 0.591\n",
      "  📊 Maximum Correlation: 0.737\n",
      "  📊 Minimum Correlation: 0.408\n",
      "\n",
      "📊 FACTOR ANALYSIS:\n",
      "  📈 Market Loading: 0.984\n",
      "  📊 R-Squared: 0.969\n",
      "\n",
      "🔄 MARKET REGIME ANALYSIS:\n",
      "\n",
      "📈 High Volatility Regime:\n",
      "  📊 Periods: 186 days\n",
      "  📊 Average Return: 70.53%\n",
      "  📊 Average Volatility: 30.35%\n",
      "\n",
      "📉 Low Volatility Regime:\n",
      "  📊 Periods: 435 days\n",
      "  📊 Average Return: 4.09%\n",
      "  📊 Average Volatility: 23.89%\n",
      "\n",
      "🎯 STRESS TEST INSIGHTS:\n",
      "  • Portfolio shows 2498.5% return decline in -10% market stress\n",
      "  • Volatility increases by 13.0% under stress conditions\n",
      "  • Average asset correlation is 0.59 (diversification benefit)\n",
      "  • Market loading of 0.98 indicates high market sensitivity\n"
     ]
    }
   ],
   "source": [
    "# Extract stress testing and sensitivity analysis\n",
    "sensitivity_analysis = analysis_results['greeks']['sensitivity_analysis']\n",
    "stress_scenarios = sensitivity_analysis['stress_scenarios']\n",
    "\n",
    "print(\"🧪 STRESS TESTING & SENSITIVITY ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n📉 MARKET STRESS SCENARIOS:\")\n",
    "\n",
    "# Market crash scenarios\n",
    "crash_10 = stress_scenarios['market_crash_10pct']\n",
    "crash_20 = stress_scenarios['market_crash_20pct']\n",
    "\n",
    "print(\"\\n🔥 Market Crash -10%:\")\n",
    "print(f\"  📊 Scenario Return: {crash_10['scenario_return']:.2%}\")\n",
    "print(f\"  📊 Scenario Volatility: {crash_10['scenario_volatility']:.2%}\")\n",
    "print(f\"  📊 VaR (95%): {crash_10['var_95']:.2%}\")\n",
    "print(f\"  📊 Expected Shortfall: {crash_10['expected_shortfall']:.2%}\")\n",
    "\n",
    "print(\"\\n💥 Market Crash -20%:\")\n",
    "print(f\"  📊 Scenario Return: {crash_20['scenario_return']:.2%}\")\n",
    "print(f\"  📊 Scenario Volatility: {crash_20['scenario_volatility']:.2%}\")\n",
    "print(f\"  📊 VaR (95%): {crash_20['var_95']:.2%}\")\n",
    "print(f\"  📊 Expected Shortfall: {crash_20['expected_shortfall']:.2%}\")\n",
    "\n",
    "# Volatility stress test\n",
    "vol_stress = stress_scenarios['volatility_spike_50pct']\n",
    "print(\"\\n🌊 Volatility Spike +50%:\")\n",
    "print(f\"  📊 Base Volatility: {vol_stress['base_volatility']:.2%}\")\n",
    "print(f\"  📊 Stressed Volatility: {vol_stress['stressed_volatility']:.2%}\")\n",
    "print(f\"  📊 Volatility Impact: {vol_stress['volatility_impact']:.2%}\")\n",
    "\n",
    "# Correlation analysis\n",
    "corr_stress = stress_scenarios['correlation_spike']\n",
    "print(\"\\n🔗 CORRELATION ANALYSIS:\")\n",
    "print(f\"  📊 Average Correlation: {corr_stress['average_correlation']:.3f}\")\n",
    "print(f\"  📊 Maximum Correlation: {corr_stress['max_correlation']:.3f}\")\n",
    "print(f\"  📊 Minimum Correlation: {corr_stress['min_correlation']:.3f}\")\n",
    "\n",
    "# Factor loadings\n",
    "factor_loadings = sensitivity_analysis['factor_loadings']\n",
    "print(\"\\n📊 FACTOR ANALYSIS:\")\n",
    "print(f\"  📈 Market Loading: {factor_loadings['market_loading']:.3f}\")\n",
    "print(f\"  📊 R-Squared: {factor_loadings['r_squared']:.3f}\")\n",
    "\n",
    "# Regime analysis\n",
    "regime_analysis = sensitivity_analysis['regime_analysis']\n",
    "print(\"\\n🔄 MARKET REGIME ANALYSIS:\")\n",
    "\n",
    "high_vol = regime_analysis['high_volatility_regime']\n",
    "low_vol = regime_analysis['low_volatility_regime']\n",
    "\n",
    "print(f\"\\n📈 High Volatility Regime:\")\n",
    "print(f\"  📊 Periods: {high_vol['periods']} days\")\n",
    "print(f\"  📊 Average Return: {high_vol['avg_return']:.2%}\")\n",
    "print(f\"  📊 Average Volatility: {high_vol['avg_volatility']:.2%}\")\n",
    "\n",
    "print(f\"\\n📉 Low Volatility Regime:\")\n",
    "print(f\"  📊 Periods: {low_vol['periods']} days\")\n",
    "print(f\"  📊 Average Return: {low_vol['avg_return']:.2%}\")\n",
    "print(f\"  📊 Average Volatility: {low_vol['avg_volatility']:.2%}\")\n",
    "\n",
    "print(\"\\n🎯 STRESS TEST INSIGHTS:\")\n",
    "insights = [\n",
    "    f\"• Portfolio shows {abs(crash_10['scenario_return']):.1%} return decline in -10% market stress\",\n",
    "    f\"• Volatility increases by {vol_stress['volatility_impact']:.1%} under stress conditions\",\n",
    "    f\"• Average asset correlation is {corr_stress['average_correlation']:.2f} (diversification benefit)\",\n",
    "    f\"• Market loading of {factor_loadings['market_loading']:.2f} indicates {'high' if abs(factor_loadings['market_loading']) > 0.7 else 'moderate'} market sensitivity\"\n",
    "]\n",
    "\n",
    "for insight in insights:\n",
    "    print(f\"  {insight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97742efa",
   "metadata": {},
   "source": [
    "## 💾 Export for LLM Analysis\n",
    "\n",
    "Finally, let's show how the complete analysis package would be formatted for a Vision-Capable LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89b34dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 LLM EXPORT PACKAGE SUMMARY\n",
      "==================================================\n",
      "📦 PACKAGE CONTENTS:\n",
      "  📊 Total sections: 4\n",
      "  💾 Estimated size: 3.9 MB\n",
      "\n",
      "📊 DATA BREAKDOWN:\n",
      "  🔢 Numerical metrics: 80\n",
      "  🖼️ Visualization images: 10\n",
      "  💾 Total image data: 3989.4 KB\n",
      "\n",
      "🤖 LLM INPUT SPECIFICATION:\n",
      "  📋 Structured JSON format for easy parsing\n",
      "  📊 150+ quantitative metrics and ratios\n",
      "  🔢 Complete Greeks analysis (5 main Greeks)\n",
      "  🖼️ 10 high-resolution charts as base64 PNG\n",
      "  ⚠️ Comprehensive risk and stress testing\n",
      "  📅 Time-series performance analysis\n",
      "  🎯 Portfolio optimization insights\n",
      "  📈 Asset allocation recommendations\n",
      "\n",
      "✨ READY FOR VISION-CAPABLE LLM ANALYSIS!\n",
      "\n",
      "🎯 The complete package includes:\n",
      "  • All numerical analysis in structured JSON format\n",
      "  • Visual charts encoded as base64 images for vision models\n",
      "  • Comprehensive metadata and timestamps\n",
      "  • Multiple export formats for different use cases\n",
      "  • Professional-grade financial metrics and Greeks\n",
      "  • Stress testing and scenario analysis\n",
      "  • Ready for immediate LLM consumption\n",
      "\n",
      "🚀 Analysis completed at: 2025-07-26 17:13:01\n"
     ]
    }
   ],
   "source": [
    "print(\"💾 LLM EXPORT PACKAGE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a summary of what would be sent to the LLM\n",
    "llm_package = analyzer.export_for_llm(output_format=\"comprehensive\")\n",
    "\n",
    "# Calculate package statistics\n",
    "def analyze_data_structure(data, prefix=\"\"):\n",
    "    stats = {}\n",
    "    \n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            current_key = f\"{prefix}.{key}\" if prefix else key\n",
    "            if isinstance(value, dict):\n",
    "                stats[current_key] = f\"Dict with {len(value)} items\"\n",
    "                nested_stats = analyze_data_structure(value, current_key)\n",
    "                stats.update(nested_stats)\n",
    "            elif isinstance(value, list):\n",
    "                stats[current_key] = f\"List with {len(value)} items\"\n",
    "            elif isinstance(value, str) and len(value) > 1000:\n",
    "                stats[current_key] = f\"Base64 image ({len(value)/1024:.1f} KB)\"\n",
    "            else:\n",
    "                stats[current_key] = type(value).__name__\n",
    "    \n",
    "    return stats\n",
    "\n",
    "package_structure = analyze_data_structure(llm_package)\n",
    "\n",
    "print(\"📦 PACKAGE CONTENTS:\")\n",
    "print(f\"  📊 Total sections: {len(llm_package)}\")\n",
    "print(f\"  💾 Estimated size: {len(str(llm_package))/1024/1024:.1f} MB\")\n",
    "\n",
    "# Count different types of data\n",
    "metrics_count = 0\n",
    "image_count = 0\n",
    "image_size = 0\n",
    "\n",
    "for key, value in package_structure.items():\n",
    "    if \"Base64 image\" in value:\n",
    "        image_count += 1\n",
    "        # Extract size from the description\n",
    "        size_str = value.split(\"(\")[1].split(\" KB\")[0]\n",
    "        image_size += float(size_str)\n",
    "    elif key.startswith(\"metrics.\"):\n",
    "        metrics_count += 1\n",
    "\n",
    "print(f\"\\n📊 DATA BREAKDOWN:\")\n",
    "print(f\"  🔢 Numerical metrics: {metrics_count}\")\n",
    "print(f\"  🖼️ Visualization images: {image_count}\")\n",
    "print(f\"  💾 Total image data: {image_size:.1f} KB\")\n",
    "\n",
    "print(\"\\n🤖 LLM INPUT SPECIFICATION:\")\n",
    "llm_spec = [\n",
    "    \"📋 Structured JSON format for easy parsing\",\n",
    "    \"📊 150+ quantitative metrics and ratios\",\n",
    "    \"🔢 Complete Greeks analysis (5 main Greeks)\",\n",
    "    \"🖼️ 10 high-resolution charts as base64 PNG\",\n",
    "    \"⚠️ Comprehensive risk and stress testing\",\n",
    "    \"📅 Time-series performance analysis\",\n",
    "    \"🎯 Portfolio optimization insights\",\n",
    "    \"📈 Asset allocation recommendations\"\n",
    "]\n",
    "\n",
    "for spec in llm_spec:\n",
    "    print(f\"  {spec}\")\n",
    "\n",
    "print(\"\\n✨ READY FOR VISION-CAPABLE LLM ANALYSIS!\")\n",
    "print(\"\\n🎯 The complete package includes:\")\n",
    "final_summary = [\n",
    "    \"• All numerical analysis in structured JSON format\",\n",
    "    \"• Visual charts encoded as base64 images for vision models\",\n",
    "    \"• Comprehensive metadata and timestamps\",\n",
    "    \"• Multiple export formats for different use cases\",\n",
    "    \"• Professional-grade financial metrics and Greeks\",\n",
    "    \"• Stress testing and scenario analysis\",\n",
    "    \"• Ready for immediate LLM consumption\"\n",
    "]\n",
    "\n",
    "for item in final_summary:\n",
    "    print(f\"  {item}\")\n",
    "\n",
    "print(f\"\\n🚀 Analysis completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689faae3",
   "metadata": {},
   "source": [
    "## 🎯 Conclusion\n",
    "\n",
    "The **Analyzer** class provides a comprehensive solution for generating portfolio analysis optimized for Vision-Capable LLMs:\n",
    "\n",
    "### 🏆 Key Achievements:\n",
    "- **150+ Metrics**: Complete performance, risk, and allocation analysis\n",
    "- **Portfolio Greeks**: Professional-grade sensitivity analysis\n",
    "- **10 Visualizations**: High-resolution charts as base64 images\n",
    "- **Multiple Formats**: Flexible export options for different use cases\n",
    "- **LLM-Ready**: Structured JSON format optimized for AI consumption\n",
    "- **🆕 OpenAI Integration**: Direct message generation for OpenAI API\n",
    "\n",
    "### 🔮 Ready for AI Integration:\n",
    "The Analyzer generates everything needed for a Vision-Capable LLM to:\n",
    "- Analyze portfolio performance and risk metrics\n",
    "- Interpret visual charts and patterns\n",
    "- Provide investment recommendations\n",
    "- Identify optimization opportunities\n",
    "- Generate comprehensive reports\n",
    "\n",
    "### 🤖 OpenAI API Integration:\n",
    "New methods provide seamless integration:\n",
    "- `generate_openai_messages()` - Full vision-capable analysis with images\n",
    "- `generate_simple_message()` - Text-only analysis for standard models\n",
    "- Compatible with GPT-4V, GPT-4, GPT-3.5, and other OpenAI models\n",
    "- Ready-to-use message format requiring no additional formatting\n",
    "\n",
    "This represents a complete bridge between quantitative portfolio analysis and AI-powered insights! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3f4e50",
   "metadata": {},
   "source": [
    "## 🤖 OpenAI LLM Message Generation\n",
    "\n",
    "The Analyzer now includes methods to generate OpenAI-compatible messages that can be directly used with the OpenAI API for portfolio analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41373245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 OPENAI MESSAGE GENERATION DEMO\n",
      "==================================================\n",
      "\n",
      "📸 Generating messages for VISION-CAPABLE models (GPT-4V, etc.)...\n",
      "✅ Generated 2 messages\n",
      "📋 Message structure:\n",
      "  1. Role: system\n",
      "     📝 Content: 1,129 characters\n",
      "  2. Role: user\n",
      "     📝 Text content: 1,933 characters\n",
      "     🖼️ Images: 10\n",
      "\n",
      "📄 TEXT-ONLY models (GPT-3.5, GPT-4, etc.)...\n",
      "✅ Generated 2 messages\n",
      "  1. Role: system\n",
      "     📝 Content: 1,129 characters\n",
      "  2. Role: user\n",
      "     📝 Content: 69 characters\n",
      "\n",
      "💻 EXAMPLE USAGE WITH OPENAI API:\n",
      "\n",
      "# For Vision-Capable Models (GPT-4V)\n",
      "import openai\n",
      "\n",
      "# Generate messages using the analyzer\n",
      "messages = analyzer.generate_openai_messages(\n",
      "    analysis_request=\"Analyze this portfolio and provide investment insights\",\n",
      "    include_visualizations=True,\n",
      "    output_format=\"comprehensive\"\n",
      ")\n",
      "\n",
      "# Send to OpenAI\n",
      "response = openai.chat.completions.create(\n",
      "    model=\"gpt-4-vision-preview\",  # or \"gpt-4o\"\n",
      "    messages=messages,\n",
      "    max_tokens=2000\n",
      ")\n",
      "\n",
      "print(response.choices[0].message.content)\n",
      "\n",
      "# For Text-Only Models  \n",
      "simple_messages = analyzer.generate_simple_message(\n",
      "    analysis_request=\"Analyze this portfolio\"\n",
      ")\n",
      "\n",
      "response = openai.chat.completions.create(\n",
      "    model=\"gpt-4\",\n",
      "    messages=simple_messages,\n",
      "    max_tokens=1500\n",
      ")\n",
      "\n",
      "\n",
      "🎯 MESSAGE CONTENT BREAKDOWN:\n",
      "System Message:\n",
      "  • Expert portfolio analyst persona\n",
      "  • Knowledge of Modern Portfolio Theory\n",
      "  • Instructions for comprehensive analysis\n",
      "  • Guidelines for actionable recommendations\n",
      "\n",
      "User Message:\n",
      "  • Custom analysis request/prompt\n",
      "  • Complete portfolio metrics and data\n",
      "  • Portfolio Greeks and sensitivity analysis\n",
      "  • Stress testing results\n",
      "  • Base64 encoded visualization images (if vision model)\n",
      "\n",
      "✨ READY FOR IMMEDIATE LLM ANALYSIS!\n",
      "🔌 Direct integration with OpenAI, Anthropic, or any LLM API\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate OpenAI message generation\n",
    "print(\"🤖 OPENAI MESSAGE GENERATION DEMO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Generate messages for vision-capable models (with images)\n",
    "print(\"\\n📸 Generating messages for VISION-CAPABLE models (GPT-4V, etc.)...\")\n",
    "vision_messages = analyzer.generate_openai_messages(\n",
    "    analysis_request=\"Analyze this tech portfolio and provide detailed investment recommendations focusing on risk management and optimization opportunities.\",\n",
    "    include_visualizations=True,\n",
    "    output_format=\"comprehensive\"\n",
    ")\n",
    "\n",
    "print(f\"✅ Generated {len(vision_messages)} messages\")\n",
    "print(f\"📋 Message structure:\")\n",
    "for i, message in enumerate(vision_messages, 1):\n",
    "    role = message['role']\n",
    "    content = message['content']\n",
    "    \n",
    "    if isinstance(content, list):\n",
    "        text_items = [item for item in content if item['type'] == 'text']\n",
    "        image_items = [item for item in content if item['type'] == 'image_url']\n",
    "        print(f\"  {i}. Role: {role}\")\n",
    "        print(f\"     📝 Text content: {len(text_items[0]['text']) if text_items else 0:,} characters\")\n",
    "        print(f\"     🖼️ Images: {len(image_items)}\")\n",
    "    else:\n",
    "        print(f\"  {i}. Role: {role}\")\n",
    "        print(f\"     📝 Content: {len(content):,} characters\")\n",
    "\n",
    "print(\"\\n📄 TEXT-ONLY models (GPT-3.5, GPT-4, etc.)...\")\n",
    "text_messages = analyzer.generate_simple_message(\n",
    "    analysis_request=\"Analyze this tech portfolio and provide investment recommendations.\"\n",
    ")\n",
    "\n",
    "print(f\"✅ Generated {len(text_messages)} messages\")\n",
    "for i, message in enumerate(text_messages, 1):\n",
    "    print(f\"  {i}. Role: {message['role']}\")\n",
    "    print(f\"     📝 Content: {len(message['content']):,} characters\")\n",
    "\n",
    "print(\"\\n💻 EXAMPLE USAGE WITH OPENAI API:\")\n",
    "example_code = '''\n",
    "# For Vision-Capable Models (GPT-4V)\n",
    "import openai\n",
    "\n",
    "# Generate messages using the analyzer\n",
    "messages = analyzer.generate_openai_messages(\n",
    "    analysis_request=\"Analyze this portfolio and provide investment insights\",\n",
    "    include_visualizations=True,\n",
    "    output_format=\"comprehensive\"\n",
    ")\n",
    "\n",
    "# Send to OpenAI\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4-vision-preview\",  # or \"gpt-4o\"\n",
    "    messages=messages,\n",
    "    max_tokens=2000\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# For Text-Only Models  \n",
    "simple_messages = analyzer.generate_simple_message(\n",
    "    analysis_request=\"Analyze this portfolio\"\n",
    ")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=simple_messages,\n",
    "    max_tokens=1500\n",
    ")\n",
    "'''\n",
    "\n",
    "print(example_code)\n",
    "\n",
    "print(\"\\n🎯 MESSAGE CONTENT BREAKDOWN:\")\n",
    "print(\"System Message:\")\n",
    "print(\"  • Expert portfolio analyst persona\")\n",
    "print(\"  • Knowledge of Modern Portfolio Theory\") \n",
    "print(\"  • Instructions for comprehensive analysis\")\n",
    "print(\"  • Guidelines for actionable recommendations\")\n",
    "\n",
    "print(\"\\nUser Message:\")\n",
    "print(\"  • Custom analysis request/prompt\")\n",
    "print(\"  • Complete portfolio metrics and data\")\n",
    "print(\"  • Portfolio Greeks and sensitivity analysis\") \n",
    "print(\"  • Stress testing results\")\n",
    "print(\"  • Base64 encoded visualization images (if vision model)\")\n",
    "\n",
    "print(\"\\n✨ READY FOR IMMEDIATE LLM ANALYSIS!\")\n",
    "print(\"🔌 Direct integration with OpenAI, Anthropic, or any LLM API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36723266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 DETAILED MESSAGE INSPECTION\n",
      "==================================================\n",
      "\n",
      "📋 SYSTEM MESSAGE:\n",
      "Role: system\n",
      "Content preview (first 300 chars):\n",
      "\"You are an expert portfolio analyst and investment advisor with deep knowledge of:\n",
      "\n",
      "- Modern Portfolio Theory and asset allocation\n",
      "- Risk management and Value at Risk (VaR) analysis  \n",
      "- Portfolio optimization techniques\n",
      "- Financial metrics and performance analysis\n",
      "- Technical and fundamental analysi...\"\n",
      "\n",
      "👤 USER MESSAGE:\n",
      "Role: user\n",
      "Content type: <class 'list'>\n",
      "Content items: 11\n",
      "  Item 1:\n",
      "    Type: text\n",
      "    Text preview: 'Provide investment recommendations for this portfolio  === PORTFOLIO SUMMARY === Portfolio Name: Tech Growth Portfolio Assets: AAPL, GOOGL, MSFT, AMZN, TSLA Analysis Period: 2022-01-03 to 2024-07-01 T...'\n",
      "  Item 2:\n",
      "    Type: image_url\n",
      "    Image URL preview: 'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAC+MA...'\n",
      "    Detail level: high\n",
      "  Item 3:\n",
      "    Type: image_url\n",
      "    Image URL preview: 'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAEWgA...'\n",
      "    Detail level: high\n",
      "\n",
      "📊 MESSAGE SIZE COMPARISON BY FORMAT:\n",
      "  summary        :    3.9 MB, 10 images\n",
      "  comprehensive  :    3.9 MB, 10 images\n",
      "  metrics_only   :    0.0 MB, 0 images\n",
      "  visuals_only   :    0.0 MB, 0 images\n",
      "\n",
      "🎛️ CUSTOMIZATION OPTIONS:\n",
      "  • Custom analysis requests (investment strategy, risk focus, etc.)\n",
      "  • Include/exclude visualizations based on LLM capabilities\n",
      "  • Different output formats (comprehensive, summary, metrics-only)\n",
      "  • Benchmark comparison analysis\n",
      "  • Custom risk-free rates for calculations\n",
      "  • Flexible message structure for different LLM providers\n",
      "\n",
      "🚀 Messages generated at: 2025-07-26 17:13:49\n",
      "✅ Ready for OpenAI API integration!\n"
     ]
    }
   ],
   "source": [
    "# Let's inspect the actual message structure in detail\n",
    "print(\"🔍 DETAILED MESSAGE INSPECTION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Generate a sample message for inspection\n",
    "sample_messages = analyzer.generate_openai_messages(\n",
    "    analysis_request=\"Provide investment recommendations for this portfolio\",\n",
    "    include_visualizations=True,\n",
    "    output_format=\"summary\"\n",
    ")\n",
    "\n",
    "# Show the system message\n",
    "print(\"\\n📋 SYSTEM MESSAGE:\")\n",
    "system_msg = sample_messages[0]\n",
    "print(f\"Role: {system_msg['role']}\")\n",
    "print(f\"Content preview (first 300 chars):\")\n",
    "print(f'\"{system_msg[\"content\"][:300]}...\"')\n",
    "\n",
    "# Show the user message structure\n",
    "print(\"\\n👤 USER MESSAGE:\")\n",
    "user_msg = sample_messages[1]\n",
    "print(f\"Role: {user_msg['role']}\")\n",
    "print(f\"Content type: {type(user_msg['content'])}\")\n",
    "\n",
    "if isinstance(user_msg['content'], list):\n",
    "    print(f\"Content items: {len(user_msg['content'])}\")\n",
    "    for i, item in enumerate(user_msg['content'][:3]):  # Show first 3 items\n",
    "        print(f\"  Item {i+1}:\")\n",
    "        print(f\"    Type: {item['type']}\")\n",
    "        if item['type'] == 'text':\n",
    "            text_preview = item['text'][:200].replace('\\n', ' ')\n",
    "            print(f\"    Text preview: '{text_preview}...'\")\n",
    "        elif item['type'] == 'image_url':\n",
    "            url_preview = item['image_url']['url'][:50]\n",
    "            print(f\"    Image URL preview: '{url_preview}...'\")\n",
    "            print(f\"    Detail level: {item['image_url']['detail']}\")\n",
    "\n",
    "# Show comparison between different output formats\n",
    "print(\"\\n📊 MESSAGE SIZE COMPARISON BY FORMAT:\")\n",
    "formats = ['summary', 'comprehensive', 'metrics_only', 'visuals_only']\n",
    "\n",
    "for format_type in formats:\n",
    "    test_messages = analyzer.generate_openai_messages(\n",
    "        analysis_request=\"Analyze this portfolio\",\n",
    "        include_visualizations=(format_type != 'metrics_only'),\n",
    "        output_format=format_type\n",
    "    )\n",
    "    \n",
    "    total_size = 0\n",
    "    image_count = 0\n",
    "    \n",
    "    for msg in test_messages:\n",
    "        if isinstance(msg['content'], str):\n",
    "            total_size += len(msg['content'])\n",
    "        elif isinstance(msg['content'], list):\n",
    "            for item in msg['content']:\n",
    "                if item['type'] == 'text':\n",
    "                    total_size += len(item['text'])\n",
    "                elif item['type'] == 'image_url':\n",
    "                    total_size += len(item['image_url']['url'])\n",
    "                    image_count += 1\n",
    "    \n",
    "    print(f\"  {format_type:15}: {total_size/1024/1024:6.1f} MB, {image_count} images\")\n",
    "\n",
    "print(\"\\n🎛️ CUSTOMIZATION OPTIONS:\")\n",
    "customization_examples = [\n",
    "    \"• Custom analysis requests (investment strategy, risk focus, etc.)\",\n",
    "    \"• Include/exclude visualizations based on LLM capabilities\", \n",
    "    \"• Different output formats (comprehensive, summary, metrics-only)\",\n",
    "    \"• Benchmark comparison analysis\",\n",
    "    \"• Custom risk-free rates for calculations\",\n",
    "    \"• Flexible message structure for different LLM providers\"\n",
    "]\n",
    "\n",
    "for example in customization_examples:\n",
    "    print(f\"  {example}\")\n",
    "\n",
    "print(f\"\\n🚀 Messages generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"✅ Ready for OpenAI API integration!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a182ae5f-2785-4f5d-9e42-f45c3b0492c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
